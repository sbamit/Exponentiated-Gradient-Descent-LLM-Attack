{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "# file_path_pgd : str = 'output_loss_001_llama2_pgd.json'\n",
    "# file_path_pgd : str = './output_Exp_Grad_Descent_w_Gumbel_SoftMax_Llama2(Ten_behaviors_1kIterations).json'\n",
    "file_path_pgd : str = './output_EGD_w_Entropy(only_ASCII_init)_20_behaviors(1000_iterations).json'\n",
    "# Load the JSON file\n",
    "with open(file_path_pgd, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Process each JSON object\n",
    "losses = []\n",
    "harmul_behaviors = []\n",
    "adv_suffixes = []\n",
    "count = 1\n",
    "for item in data[:]:\n",
    "    print(f'\\n\\n{count}',end=' ')\n",
    "    print('_' * 120)\n",
    "    harmful_behaviour = item.get('harmful-behaviour')\n",
    "    suffix_token_ids = item.get('suffix_token_ids')\n",
    "    target = item.get('target')\n",
    "    loss = item.get(\"continuous_loss\")\n",
    "    outputs = item.get('outputs')\n",
    "\n",
    "    # Print extracted information\n",
    "    print(f\"Harmful Behaviour: {harmful_behaviour}\")\n",
    "    print(f\"Suffix Token IDs: {suffix_token_ids}\")\n",
    "    print(f\"Target: {target}\")\n",
    "    # print(f\"Loss: {loss}\")\n",
    "    losses.append(loss)\n",
    "    harmul_behaviors.append(harmful_behaviour)\n",
    "    adv_suffixes.append(suffix_token_ids)\n",
    "    i=1\n",
    "    for output in outputs:\n",
    "        print(f'\\n#{i} \\n{output}')\n",
    "        i+=1\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list to a NumPy array\n",
    "numbers_array = np.array(losses)\n",
    "# print(numbers_array)\n",
    "# Compute the mean of the array\n",
    "mean_value = np.mean(numbers_array)\n",
    "\n",
    "# Print the mean value\n",
    "print(\"Mean value:\", mean_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the indices that failed in original trial\n",
    "# Indices you want to select\n",
    "indices = [2, 7, 13, 14, 16, 17, 19, 20, 22, 23, 29, 32, 33, 43, 48, 49, 51, 63, 71, 75, 76, 78, 81, 83, 86, 88, 92, 95, 98]\n",
    "failed_suffixes = [adv_suffixes[i] for i in indices]\n",
    "failed_behaviors = [harmul_behaviors[i] for i in indices]\n",
    "\n",
    "for i in range(len(failed_behaviors)):\n",
    "    print(failed_behaviors[i],end=', ')\n",
    "    # print(failed_suffixes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now load Llama-2 model to generate harmful behaviors\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tqdm as tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_path: str = \"/home/samuel/research/llmattacks/llm-attacks/DIR/llama-2/llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "def load_model_and_tokenizer(model_path, tokenizer_path=None, device=\"cuda:0\", **kwargs):\n",
    "    # from llm-attacks\n",
    "    model = (\n",
    "        AutoModelForCausalLM.from_pretrained(\n",
    "            model_path, torch_dtype=torch.float16, trust_remote_code=True, **kwargs\n",
    "        ).to(device).eval()\n",
    "    )\n",
    "\n",
    "    tokenizer_path = model_path if tokenizer_path is None else tokenizer_path\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        tokenizer_path, trust_remote_code=True, use_fast=False\n",
    "    )\n",
    "\n",
    "    if \"llama-2\" in tokenizer_path:\n",
    "        tokenizer.pad_token = tokenizer.unk_token\n",
    "        tokenizer.padding_side = \"left\"\n",
    "    if not tokenizer.pad_token:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "model, tokenizer = load_model_and_tokenizer(\n",
    "        model_path, low_cpu_mem_usage=True, use_cache=False, device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(input_string):\n",
    "    return torch.tensor(tokenizer(input_string)[\"input_ids\"], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a for loop, take each failed_behaviors and failed_suffixes then model.generate\n",
    "for i in tqdm(range(len(failed_behaviors))):\n",
    "    print(f'\\n\\n{i+1}',end=' ')\n",
    "    print('_' * 120)\n",
    "    print(\"Harmful Behaviour:\", failed_behaviors[i])\n",
    "    user_prompt_ids = get_tokens(failed_behaviors[i]).to(device)\n",
    "    adv_prompt_ids = torch.tensor(failed_suffixes[i]).to(device)\n",
    "    # print(user_prompt_ids) print(adv_prompt_ids)\n",
    "    input_ids = torch.hstack([user_prompt_ids, adv_prompt_ids]).to(device)\n",
    "    # = torch.tensor(combined_ids).to(device)\n",
    "    # print(tokenizer.decode(input_ids, skip_special_tokens=True))\n",
    "    for trial in range(10):\n",
    "        print(f'\\nTrial #{trial+1}',end=' ')\n",
    "        print(' -- ' * 20)\n",
    "        generated_text = model.generate(input_ids.unsqueeze(0), max_length=200)[0]\n",
    "        print(tokenizer.decode(generated_text, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-embedding-attack_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
