{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Loss values w.r.t time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def read_csv_line_by_line(gcg_loss_file_path):\n",
    "    # Step 1: Read the CSV file line-by-line\n",
    "    with open(gcg_loss_file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Step 2: Split each line into a list of values\n",
    "    rows = [line.strip().split(',') for line in lines]\n",
    "\n",
    "    # Step 3: Determine the maximum number of columns\n",
    "    max_columns = max(len(row) for row in rows)\n",
    "\n",
    "    # Step 4: Pad each row to ensure they all have the same number of columns\n",
    "    for row in rows:\n",
    "        while len(row) < max_columns:\n",
    "            row.append('')  # Padding with empty string\n",
    "\n",
    "    # Step 5: Convert the list of lists into a pandas DataFrame\n",
    "    df_gcg_loss = pd.DataFrame(rows)\n",
    "\n",
    "    # Optional: Set the first row as the header if the CSV has headers\n",
    "    # df_gcg_loss.columns = df_gcg_loss.iloc[0]\n",
    "    # df_gcg_loss = df_gcg_loss.drop(0).reset_index(drop=True)\n",
    "    return df_gcg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MAX_COL = 300\n",
    "# Replace 'your_file.csv' with the path to your actual CSV file\n",
    "# Regularized Relaxed Attack\n",
    "ce_loss_file_path = './results/_ce_loss_rr_25_llama2.csv'\n",
    "# PGD attack\n",
    "cont_loss_file_path = './results/_cont_loss_pgd_25_llama2.csv'\n",
    "# GCG attack\n",
    "gcg_loss_file_path = './results/ce_loss_gcg_25_llama2_MEDIAN.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have the data now.\n",
    "# Plot the graphs w.r.t. time rather than epochs \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_ce_loss = pd.read_csv(ce_loss_file_path)\n",
    "df_pgd_loss = pd.read_csv(cont_loss_file_path)\n",
    "df_gcg_loss =  read_csv_line_by_line(gcg_loss_file_path)\n",
    "# df_ce_loss = df_ce_loss.iloc[:,:]\n",
    "# print(ce_loss_column_medians)\n",
    "df_pgd_loss.fillna(0, inplace=True)\n",
    "df_ce_loss.fillna(0, inplace=True)\n",
    "df_gcg_loss.fillna(0, inplace=True)\n",
    "# print(df_gcg_loss)\n",
    "ce_loss_column_medians = df_ce_loss.median()\n",
    "pgd_loss_column_medians = df_pgd_loss.median()\n",
    "gcg_loss_column_medians = df_gcg_loss.iloc[-1]\n",
    "# print(gcg_loss_column_medians)\n",
    "# Step 1: Reshape the series to group every 6 values\n",
    "# Calculate the number of complete groups of 6\n",
    "# ce_loss_num_groups = len(ce_loss_column_medians) // 7\n",
    "# pgd_loss_num_gropus = len(pgd_loss_column_medians) // 6\n",
    "# Trim the series to make its length a multiple of 6\n",
    "# ce_loss_trimmed_data = ce_loss_column_medians.iloc[:ce_loss_num_groups * 7]\n",
    "# pgd_loss_trimmed_data = pgd_loss_column_medians.iloc[:pgd_loss_num_gropus*6]\n",
    "# Step 2: Reshape and calculate the mean for each group\n",
    "# ce_loss_reshaped_data = ce_loss_trimmed_data.values.reshape(-1, 7)\n",
    "# ce_loss_group_means = ce_loss_reshaped_data.mean(axis=1)\n",
    "\n",
    "# pgd_loss_reshaped_data = pgd_loss_trimmed_data.values.reshape(-1,6)\n",
    "# pgd_loss_group_means = pgd_loss_reshaped_data.mean(axis=1)\n",
    "# Step 3: Create a new Series from the means\n",
    "# ce_loss_compressed = pd.Series(ce_loss_group_means)\n",
    "# ce_loss_x_vals = ce_loss_compressed.index.values\n",
    "# ce_loss_y_vals = ce_loss_compressed.values\n",
    "ce_loss_x_vals = np.linspace(0, 120, len(ce_loss_column_medians))\n",
    "ce_loss_y_vals = pd.to_numeric(ce_loss_column_medians, errors='coerce').tolist()\n",
    "# Convert the numeric Series to a list of numbers\n",
    "# numeric_series = numeric_series.tolist()\n",
    "# print(ce_loss_compressed)\n",
    "# pgd_loss_compressed = pd.Series(pgd_loss_group_means)\n",
    "# pgd_loss_x_vals = pgd_loss_compressed.index.values\n",
    "# pgd_loss_y_vals = pgd_loss_compressed.values\n",
    "pgd_loss_x_vals = np.linspace(0, 120, len(pgd_loss_column_medians))\n",
    "pgd_loss_y_vals = pd.to_numeric(pgd_loss_column_medians, errors='coerce').tolist()\n",
    "# Convert the numeric Series to a list of numbers\n",
    "# print(pgd_loss_compressed)\n",
    "float_list = np.linspace(0, 1000, len(gcg_loss_column_medians))\n",
    "gcg_loss_x_vals = list(map(int, float_list))\n",
    "# Convert the Series to numeric type\n",
    "gcg_loss_y_vals = pd.to_numeric(gcg_loss_column_medians, errors='coerce').tolist()\n",
    "# Convert the numeric Series to a list of numbers\n",
    "# = numeric_series\n",
    "# gcg_loss_y_vals = gcg_loss_column_medians.tolist()\n",
    "# print(gcg_loss_x_vals,'\\n', gcg_loss_y_vals)\n",
    "\n",
    "# Manually put a value to make the graph looks better\n",
    "# ce_loss_x_vals[0] = 1.0\n",
    "# Plot the graph with x,y values\n",
    "# Create a new figure\n",
    "plt.figure()\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "# Plot the first group of x, y values\n",
    "plt.plot(ce_loss_x_vals, ce_loss_y_vals, label='RR', marker='')\n",
    "\n",
    "# Plot the second group of x, y values\n",
    "plt.plot(pgd_loss_x_vals, pgd_loss_y_vals, label='PGD', marker='')\n",
    "\n",
    "# Plot the third group of x, y values\n",
    "plt.plot(gcg_loss_x_vals, gcg_loss_y_vals, label='GCG', marker='')\n",
    "\n",
    "# Set x-axis to logarithmic scale\n",
    "plt.xscale('log')\n",
    "# Adjust the upper limit as needed\n",
    "plt.ylim(0, 2.0)  \n",
    "# Add gridlines\n",
    "# Add gridlines for both major and minor ticks with a denser grid\n",
    "plt.grid(which='both', linestyle='-', linewidth='0.5', color='gray')\n",
    "\n",
    "# Add title and labels\n",
    "# plt.title('Cross Entropy Loss')\n",
    "plt.xlabel('Runtime s')\n",
    "plt.ylabel('Median Cross Entropy')\n",
    "\n",
    "# Add a legend\n",
    "# plt.legend()\n",
    "# plt.legend(loc='upper center', bbox_to_anchor=(1, 1), ncol=1)\n",
    "# plt.legend(loc='upper left', bbox_to_anchor=(1.05, 1), ncol=1)\n",
    "# Add a legend on top of the plot\n",
    "# plt.legend(loc='lower center', bbox_to_anchor=(0.5, 1.02), ncol=3, borderaxespad=0., frameon=False)\n",
    "plt.legend(loc='lower center', bbox_to_anchor=(0.5, 1.02), ncol=3, borderaxespad=0., frameon=True, framealpha=0.6, edgecolor='black', fancybox=False)\n",
    "\n",
    "# Adjust layout to make room for the legend\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.9])\n",
    "# Save the plot as a PDF file\n",
    "# plt.savefig('loss_vs_runtime_llama2.pdf', format='pdf')\n",
    "plt.savefig('loss_vs_runtime_llama2.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "# plt.plot(ce_loss_compressed, marker='.', linestyle='-', color='b', label='ce_loss')\n",
    "# plt.plot(pgd_loss_compressed, marker='.', linestyle='-', color='r', label='cont_loss')\n",
    "# plt.title('Loss vs Epochs (regularized relaxation)')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Median Loss')\n",
    "# plt.grid(True)\n",
    "# plt.xticks(ticks=range(0, 120, 10), labels=range(0, 120, 10), rotation=60)\n",
    "# # Add a legend to differentiate between the two files\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "# print(\"Original Series:\")\n",
    "# print(len(ce_loss_column_medians))\n",
    "# print(\"\\nCompressed Series:\")\n",
    "# print(len(compressed_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_COL = 300\n",
    "# CSV files for Gunaco model.\n",
    "# Regularized Relaxed Attack\n",
    "ce_loss_file_path = './results/ce_loss_rr_25_guanaco7bhf.csv'\n",
    "# PGD attack\n",
    "cont_loss_file_path = './results/cont_loss_pgd_25_gunaco_MEDIAN.csv'\n",
    "# GCG attack\n",
    "gcg_loss_file_path = './results/ce_loss_gcg_25_guanaco7bhf_MEDIAN.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have the data now.\n",
    "# Plot the graphs w.r.t. time rather than epochs \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_ce_loss = pd.read_csv(ce_loss_file_path)\n",
    "df_pgd_loss = pd.read_csv(cont_loss_file_path)\n",
    "df_gcg_loss =  read_csv_line_by_line(gcg_loss_file_path)\n",
    "# df_ce_loss = df_ce_loss.iloc[:,:]\n",
    "# print(ce_loss_column_medians)\n",
    "df_pgd_loss.fillna(0, inplace=True)\n",
    "df_ce_loss.fillna(0, inplace=True)\n",
    "df_gcg_loss.fillna(0, inplace=True)\n",
    "# print(df_gcg_loss)\n",
    "# Fix df_pgd_loss\n",
    "df_pgd_loss = df_pgd_loss.drop(df_pgd_loss.columns[0], axis=1) # Remove the first Column (Loss is too high)\n",
    "df_pgd_loss = df_pgd_loss.iloc[:-1] # Remove the last row, its median.\n",
    "ce_loss_column_medians = df_ce_loss.median()\n",
    "pgd_loss_column_medians = df_pgd_loss.median()\n",
    "gcg_loss_column_medians = df_gcg_loss.iloc[-1]\n",
    "# print(gcg_loss_column_medians)\n",
    "# Step 1: Reshape the series to group every 6 values\n",
    "# Calculate the number of complete groups of 6\n",
    "# ce_loss_num_groups = len(ce_loss_column_medians) // 7\n",
    "# pgd_loss_num_gropus = len(pgd_loss_column_medians) // 6\n",
    "# Trim the series to make its length a multiple of 6\n",
    "# ce_loss_trimmed_data = ce_loss_column_medians.iloc[:ce_loss_num_groups * 7]\n",
    "# pgd_loss_trimmed_data = pgd_loss_column_medians.iloc[:pgd_loss_num_gropus*6]\n",
    "# Step 2: Reshape and calculate the mean for each group\n",
    "# ce_loss_reshaped_data = ce_loss_trimmed_data.values.reshape(-1, 7)\n",
    "# ce_loss_group_means = ce_loss_reshaped_data.mean(axis=1)\n",
    "\n",
    "# pgd_loss_reshaped_data = pgd_loss_trimmed_data.values.reshape(-1,6)\n",
    "# pgd_loss_group_means = pgd_loss_reshaped_data.mean(axis=1)\n",
    "# Step 3: Create a new Series from the means\n",
    "# ce_loss_compressed = pd.Series(ce_loss_group_means)\n",
    "# ce_loss_x_vals = ce_loss_compressed.index.values\n",
    "# ce_loss_y_vals = ce_loss_compressed.values\n",
    "ce_loss_x_vals = np.linspace(0, 120, len(ce_loss_column_medians))\n",
    "ce_loss_y_vals = pd.to_numeric(ce_loss_column_medians, errors='coerce').tolist()\n",
    "# Convert the numeric Series to a list of numbers\n",
    "# numeric_series = numeric_series.tolist()\n",
    "# print(ce_loss_compressed)\n",
    "# pgd_loss_compressed = pd.Series(pgd_loss_group_means)\n",
    "# pgd_loss_x_vals = pgd_loss_compressed.index.values\n",
    "# pgd_loss_y_vals = pgd_loss_compressed.values\n",
    "pgd_loss_x_vals = np.linspace(0, 120, len(pgd_loss_column_medians))\n",
    "pgd_loss_y_vals = pd.to_numeric(pgd_loss_column_medians, errors='coerce').tolist()\n",
    "# Convert the numeric Series to a list of numbers\n",
    "# print(pgd_loss_compressed)\n",
    "float_list = np.linspace(0, 1000, len(gcg_loss_column_medians))\n",
    "gcg_loss_x_vals = list(map(int, float_list))\n",
    "# Convert the Series to numeric type\n",
    "gcg_loss_y_vals = pd.to_numeric(gcg_loss_column_medians, errors='coerce').tolist()\n",
    "# Convert the numeric Series to a list of numbers\n",
    "# = numeric_series\n",
    "# gcg_loss_y_vals = gcg_loss_column_medians.tolist()\n",
    "# print(gcg_loss_x_vals,'\\n', gcg_loss_y_vals)\n",
    "\n",
    "# Manually put a value to make the graph looks better\n",
    "# ce_loss_x_vals[0] = 1.0\n",
    "# Plot the graph with x,y values\n",
    "# Create a new figure\n",
    "plt.figure()\n",
    "\n",
    "# Plot the first group of x, y values\n",
    "plt.plot(ce_loss_x_vals, ce_loss_y_vals, label='RR', marker='')\n",
    "\n",
    "# Plot the second group of x, y values\n",
    "plt.plot(pgd_loss_x_vals, pgd_loss_y_vals, label='PGD', marker='')\n",
    "\n",
    "# Plot the third group of x, y values\n",
    "plt.plot(gcg_loss_x_vals, gcg_loss_y_vals, label='GCG', marker='')\n",
    "\n",
    "# Set x-axis to logarithmic scale\n",
    "plt.xscale('log')\n",
    "# Adjust the upper limit as needed\n",
    "plt.ylim(0, 2.0)  \n",
    "# Add gridlines\n",
    "# Add gridlines for both major and minor ticks with a denser grid\n",
    "plt.grid(which='both', linestyle='-', linewidth='0.5', color='gray')\n",
    "\n",
    "# Add title and labels\n",
    "# plt.title('Cross Entropy Loss')\n",
    "plt.xlabel('Runtime s')\n",
    "plt.ylabel('Median Cross Entropy')\n",
    "\n",
    "# Add a legend\n",
    "# plt.legend()\n",
    "# plt.legend(loc='upper center', bbox_to_anchor=(1, 1), ncol=1)\n",
    "# plt.legend(loc='upper left', bbox_to_anchor=(1.05, 1), ncol=1)\n",
    "# Add a legend on top of the plot\n",
    "# plt.legend(loc='lower center', bbox_to_anchor=(0.5, 1.02), ncol=3, borderaxespad=0., frameon=False)\n",
    "plt.legend(loc='lower center', bbox_to_anchor=(0.5, 1.02), ncol=3, borderaxespad=0., frameon=True, framealpha=0.6, edgecolor='black', fancybox=False)\n",
    "\n",
    "# Adjust layout to make room for the legend\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.9])\n",
    "# Save the plot as a PDF file\n",
    "# plt.savefig('loss_vs_runtime_llama2.pdf', format='pdf')\n",
    "plt.savefig('loss_vs_runtime_llama2.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "# plt.plot(ce_loss_compressed, marker='.', linestyle='-', color='b', label='ce_loss')\n",
    "# plt.plot(pgd_loss_compressed, marker='.', linestyle='-', color='r', label='cont_loss')\n",
    "# plt.title('Loss vs Epochs (regularized relaxation)')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Median Loss')\n",
    "# plt.grid(True)\n",
    "# plt.xticks(ticks=range(0, 120, 10), labels=range(0, 120, 10), rotation=60)\n",
    "# # Add a legend to differentiate between the two files\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "# print(\"Original Series:\")\n",
    "# print(len(ce_loss_column_medians))\n",
    "# print(\"\\nCompressed Series:\")\n",
    "# print(len(compressed_series))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a pandas DataFrame\n",
    "df_ce_loss = pd.read_csv(ce_loss_file_path)\n",
    "df_cont_loss = pd.read_csv(cont_loss_file_path)\n",
    "df_disc_loss = pd.read_csv(disc_loss_file_path)\n",
    "df_gcg_loss =  read_csv_line_by_line(gcg_loss_file_path)\n",
    "# print(df_gcg_loss.iloc[0])\n",
    "\n",
    "print('# of ce_loss values', len(df_ce_loss),',',len(df_ce_loss.columns))\n",
    "print('# of PGD loss values', len(df_cont_loss),',', len(df_cont_loss.columns))\n",
    "print('# of discrete loss values ',len(df_disc_loss),',',len(df_disc_loss.columns))\n",
    "print('# of GCG loss values ',len(df_gcg_loss),',',len(df_gcg_loss.columns))\n",
    "# Ensure both DataFrames have the same number of columns by limiting to the smallest column count\n",
    "max_columns = min(df_disc_loss.shape[1], df_gcg_loss.shape[1], MAX_COL)\n",
    "df_ce_loss = df_ce_loss.iloc[:, :max_columns]\n",
    "df_cont_loss = df_cont_loss.iloc[:, :max_columns]\n",
    "df_disc_loss = df_disc_loss.iloc[:, :max_columns]\n",
    "df_gcg_loss = df_gcg_loss.iloc[:, :max_columns]\n",
    "# Replace NaN values with 0\n",
    "df_cont_loss.fillna(0, inplace=True)\n",
    "df_ce_loss.fillna(0, inplace=True)\n",
    "df_cont_loss.fillna(0, inplace=True)\n",
    "df_gcg_loss.fillna(0, inplace=True)\n",
    "# Calculate the column-wise mean\n",
    "ce_loss_column_medians = df_ce_loss.median()\n",
    "cont_loss_column_medians = df_cont_loss.median()\n",
    "disc_loss_column_means = df_disc_loss.mean()\n",
    "gcg_loss_column_medians = df_gcg_loss.median(numeric_only=None)\n",
    "# print(gcg_loss_column_medians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the column-wise mean as a line curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(ce_loss_column_medians, marker='.', linestyle='-', color='b', label='ce_loss')\n",
    "# plt.plot(cont_loss_column_means, marker='.', linestyle='-', color='r', label='cont_loss')\n",
    "plt.title('Loss vs Epochs (regularized relaxation)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Median Loss')\n",
    "plt.grid(True)\n",
    "plt.xticks(ticks=range(0, max_columns, 10), labels=range(0, max_columns, 10), rotation=60)\n",
    "# Add a legend to differentiate between the two files\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the column-wise mean as a line curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "# plt.plot(ce_loss_column_means, marker='.', linestyle='-', color='b', label='ce_loss')\n",
    "plt.plot(cont_loss_column_medians, marker='.', linestyle='-', color='r', label='cont_loss')\n",
    "plt.title('Loss vs Epochs (PGD-Continuous)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Median Loss')\n",
    "plt.grid(True)\n",
    "plt.xticks(ticks=range(0, max_columns, 10), labels=range(0, max_columns, 10), rotation=60)\n",
    "# Add a legend to differentiate between the two files\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the column-wise mean as a line curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(gcg_loss_column_medians, marker='.', linestyle='-', color='black', label='gcg_loss')\n",
    "plt.title('Loss vs Epochs (GCG)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Median Loss')\n",
    "plt.grid(True)\n",
    "plt.xticks(ticks=range(0, max_columns, 10), labels=range(0, max_columns, 10), rotation=60)\n",
    "# Add a legend to differentiate between the two files\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the column-wise mean as a line curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(disc_loss_column_means, marker='.', linestyle='-', color='g', label='discrete_loss')\n",
    "plt.title('Loss vs Epochs (PGD - Discrete)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Loss')\n",
    "plt.grid(True)\n",
    "plt.xticks(ticks=range(0, max_columns, 10), labels=range(0, max_columns, 10), rotation=60)\n",
    "# Add a legend to differentiate between the two files\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-embedding-attack_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
