{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS and GLOBALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "from helper import get_model_path, load_model_and_tokenizer, get_embedding_matrix, get_tokens, create_one_hot_and_embeddings, get_nonascii_toks\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "# from datetime import datetime\n",
    "# from livelossplot import PlotLosses \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_tokens: int = 300 \n",
    "seed: int = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Config and Samuel's directory to load different kinds of models\n",
    "# MODEL PATHS    0           1       2       3           4\n",
    "model_options = [\"Llama2\", \"Falcon\", \"MPT\", \"Vicuna\", \"Mistral\"] \n",
    "model_name = model_options[0] # Change this to load different models\n",
    "model_path: str = get_model_path(model_name=model_name)\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "model, tokenizer = load_model_and_tokenizer(\n",
    "        model_path, low_cpu_mem_usage=True, use_cache=False, device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ascii_toks = get_nonascii_toks(tokenizer, device=device).tolist()\n",
    "# Assuming device is already defined\n",
    "non_ascii_toks_tensor = torch.tensor(non_ascii_toks).to(device=device)\n",
    "\n",
    "\n",
    "def get_masked_one_hot_adv(one_hot_adv):\n",
    "    # Mask out all the non-ascii tokens and then return\n",
    "    # Step 1: Create a tensor with all the non_ascii tokens\n",
    "    top_token_ids_tensor_2d = non_ascii_toks_tensor.unsqueeze(0).repeat(20, 1)\n",
    "    \n",
    "    # Step 2: Create a mask with the same shape as one_hot_adv, initialized to zero\n",
    "    mask = torch.ones_like(one_hot_adv, dtype=torch.float16)\n",
    "\n",
    "    # Step 3: Use token_ids_init to set the corresponding indices in the mask to 1\n",
    "    # We use gather and scatter operations for this\n",
    "    mask.scatter_(1, top_token_ids_tensor_2d, 0.0)\n",
    "\n",
    "    # Step 4: Apply the mask to one_hot_adv\n",
    "    masked_one_hot_adv = one_hot_adv * mask\n",
    "    \n",
    "    return masked_one_hot_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(model, embeddings_user, embeddings_adv, embeddings_target, targets):\n",
    "    full_embeddings = torch.hstack([embeddings_user, embeddings_adv, embeddings_target])\n",
    "    logits = model(inputs_embeds=full_embeddings).logits\n",
    "    loss_slice_start = len(embeddings_user[0]) + len(embeddings_adv[0])\n",
    "    loss = nn.CrossEntropyLoss()(logits[0, loss_slice_start - 1 : -1, :], targets)\n",
    "    return loss, logits[:, loss_slice_start-1:, :]\n",
    "    # return loss, logits.to(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EGDwithAdamOptimizer(torch.optim.Optimizer):\n",
    "#     def __init__(self, params, lr=0.01, beta1=0.9, beta2=0.999, eps=1e-4, grad_clip_val=1.0):\n",
    "#         defaults = dict(lr=lr, beta1=beta1, beta2=beta2, eps=eps, grad_clip_val=grad_clip_val)\n",
    "#         super(EGDwithAdamOptimizer, self).__init__(params, defaults)\n",
    "\n",
    "#         # Initialize state variables for each parameter group\n",
    "#         for group in self.param_groups:\n",
    "#             for param in group['params']:\n",
    "#                 self.state[param] = {\n",
    "#                     'm': torch.zeros_like(param),  # First moment vector (momentum)\n",
    "#                     'v': torch.zeros_like(param),  # Second moment vector (variance)\n",
    "#                     't': 0                         # Time step\n",
    "#                 }\n",
    "\n",
    "#     def step(self, closure=None):\n",
    "#         loss = None\n",
    "#         if closure is not None:\n",
    "#             loss = closure()\n",
    "\n",
    "#         for group in self.param_groups:\n",
    "#             lr = group['lr']\n",
    "#             beta1 = group['beta1']\n",
    "#             beta2 = group['beta2']\n",
    "#             eps = group['eps']\n",
    "#             # grad_clip_val = group['grad_clip_val']\n",
    "\n",
    "#             for param in group['params']:\n",
    "#                 if param.grad is None:\n",
    "#                     continue\n",
    "\n",
    "#                 grad = param.grad\n",
    "#                 state = self.state[param]\n",
    "\n",
    "#                 # Retrieve state variables\n",
    "#                 m = state['m']\n",
    "#                 v = state['v']\n",
    "#                 t = state['t']\n",
    "\n",
    "#                 # Increment time step\n",
    "#                 t += 1\n",
    "#                 state['t'] = t\n",
    "\n",
    "#                 # Update biased first moment estimate (m) and second moment estimate (v)     \n",
    "#                 m = beta1 * m + (1 - beta1) * grad\n",
    "#                 v = beta2 * v + (1 - beta2) * torch.pow(grad, 2) \n",
    "#                 # v = beta2 * v + (1 - beta2) * (grad ** 2)\n",
    "#                 state['m'] = m\n",
    "#                 state['v'] = v\n",
    "\n",
    "#                 # Bias correction\n",
    "#                 m_hat = m / (1 - math.pow(beta1, t)) # m_hat = m / (1 - beta1 ** t)\n",
    "#                 v_hat = v / (1 - math.pow(beta2, t)) # v_hat = v / (1 - beta2 ** t)\n",
    "\n",
    "#                 # Adam-like modified gradient\n",
    "#                 modified_grad = m_hat / (torch.sqrt(v_hat) + eps)\n",
    "\n",
    "#                 with torch.no_grad():\n",
    "#                     # Exponentiated Gradient Descent update with Adam-like modifications\n",
    "#                     param.mul_(torch.exp(-lr * modified_grad))\n",
    "\n",
    "#                     # # Clamp the parameter values to avoid extreme values; ChatGPT suggests not to do this\n",
    "#                     # param.clamp_(min=1e-12, max=1e12)\n",
    "\n",
    "#                     # Normalize each row to sum up to 1, considering possible tensor shapes\n",
    "#                     if param.dim() > 1:\n",
    "#                         row_sums = param.sum(dim=1, keepdim=True) + 1e-10  # Add epsilon to avoid division by zero\n",
    "#                         param.div_(row_sums)\n",
    "#                     else:\n",
    "#                         # Handle 1D tensors or other cases if applicable\n",
    "#                         param.div_(param.sum() + 1e-10)\n",
    "\n",
    "#         return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EGDwithAdamOptimizer(torch.optim.Optimizer):\n",
    "    def __init__(self, params, lr=0.01, beta1=0.9, beta2=0.999, eps=1e-4, grad_clip_val=1.0):\n",
    "        defaults = dict(lr=lr, beta1=beta1, beta2=beta2, eps=eps, grad_clip_val=grad_clip_val)\n",
    "        super(EGDwithAdamOptimizer, self).__init__(params, defaults)\n",
    "\n",
    "        # Initialize state variables for each parameter group\n",
    "        for group in self.param_groups:\n",
    "            for param in group['params']:\n",
    "                self.state[param] = {\n",
    "                    'm': torch.zeros_like(param),  # First moment vector (momentum)\n",
    "                    'v': torch.zeros_like(param),  # Second moment vector (variance)\n",
    "                    't': 0                         # Time step\n",
    "                }\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            lr = group['lr']\n",
    "            beta1 = group['beta1']\n",
    "            beta2 = group['beta2']\n",
    "            eps = group['eps']\n",
    "            # grad_clip_val = group['grad_clip_val']\n",
    "\n",
    "            for param in group['params']:\n",
    "                if param.grad is None:\n",
    "                    continue\n",
    "\n",
    "                grad = param.grad\n",
    "                state = self.state[param]\n",
    "\n",
    "                # Retrieve state variables\n",
    "                m = state['m']\n",
    "                v = state['v']\n",
    "                t = state['t']\n",
    "\n",
    "                # Increment time step\n",
    "                t += 1\n",
    "                state['t'] = t\n",
    "\n",
    "                # # Clip gradients to avoid exploding updates; Redundant step\n",
    "                # grad = torch.clamp(grad, min=-grad_clip_val, max=grad_clip_val)\n",
    "\n",
    "                # Update biased first moment estimate (m) and second moment estimate (v)     \n",
    "                m = beta1 * m + (1 - beta1) * grad\n",
    "                v = beta2 * v + (1 - beta2) * torch.pow(grad, 2) \n",
    "                # v = beta2 * v + (1 - beta2) * (grad ** 2)\n",
    "                state['m'] = m\n",
    "                state['v'] = v\n",
    "\n",
    "                # Bias correction\n",
    "                m_hat = m / (1 - math.pow(beta1, t)) # m_hat = m / (1 - beta1 ** t)\n",
    "                v_hat = v / (1 - math.pow(beta2, t)) # v_hat = v / (1 - beta2 ** t)\n",
    "\n",
    "                # Adam-like modified gradient\n",
    "                modified_grad = m_hat / (torch.sqrt(v_hat) + eps)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    # Exponentiated Gradient Descent update with Adam-like modifications\n",
    "                    param.mul_(torch.exp(-lr * modified_grad))\n",
    "\n",
    "                    # Clamp the parameter values to avoid extreme values\n",
    "                    param.clamp_(min=1e-12, max=1e12)\n",
    "\n",
    "                    # Normalize each row to sum up to 1, considering possible tensor shapes\n",
    "                    if param.dim() > 1:\n",
    "                        row_sums = param.sum(dim=1, keepdim=True) + 1e-10  # Add epsilon to avoid division by zero\n",
    "                        param.div_(row_sums)\n",
    "                    else:\n",
    "                        # Handle 1D tensors or other cases if applicable\n",
    "                        param.div_(param.sum() + 1e-10)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEGIN ATTACK HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "embed_weights = get_embedding_matrix(model)\n",
    "# Datset options:       0           1               2                   3\n",
    "dataset_options = ['AdvBench', 'HarmBench', 'JailbreakBench', 'MaliciousInstruct']\n",
    "dataset_name = dataset_options[0]\n",
    "dataset_path: str = f\"./data/{dataset_name}/harmful_behaviors.csv\"\n",
    "\n",
    "reader = csv.reader(open(dataset_path, 'r'))\n",
    "next(reader)\n",
    "harmful_behaviors = list(reader)[0:50]\n",
    "# We can hard-code this safe_target string; probably\n",
    "# safe_target: str = \"I cannot fulfill your request. I'm just an AI.\"\n",
    "print(len(harmful_behaviors))\n",
    "for each_behavior in harmful_behaviors:\n",
    "    print(each_behavior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'model_name: {model_name}')\n",
    "print(f'dataset_name: {dataset_name}')\n",
    "print(f'vocabulary size: {tokenizer.vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try Mini-Batch Update on the one_hot_adv using EGD.\n",
    "from math import *\n",
    "import json \n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# This is a new parameter for multi-prompt adversarial suffix optimization\n",
    "batch_size = 5\n",
    "num_steps = 200\n",
    "step_size = 0.1\n",
    "# Fetch the Model's weights\n",
    "embed_weights = get_embedding_matrix(model)\n",
    "# reader = [[user_prompt, target]]\n",
    "optimization_results = []\n",
    "# Set your regularization parameter\n",
    "initial_coefficient = 1e-5\n",
    "final_coefficient = 1e-3\n",
    "\n",
    "directories = [f'./Multi-Prompt/CSV_Files/{model_name}/{dataset_name}',    # 0\n",
    "            f'./Multi-Prompt/JSON_Files/{model_name}/{dataset_name}']      # 1\n",
    "for directory in directories:\n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory '{directory}' created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory}' already exists.\")\n",
    "\n",
    "user_prompt_tokens_list =list()\n",
    "target_tokens_list = list()\n",
    "for i, row in enumerate(harmful_behaviors):\n",
    "    user_prompt, target = row\n",
    "    user_prompt_tokens_list.append(get_tokens(user_prompt, tokenizer=tokenizer, device=device) )   \n",
    "    target_tokens_list.append(get_tokens(target, tokenizer=tokenizer, device=device)[1:] )\n",
    "    \n",
    "# JSON file to dump the model generated outputs \n",
    "json_filename = f'{directories[1]}/outputs_multiprompt_using_EGD({str(len(harmful_behaviors))}_behaviors)({str(num_steps)}_steps)({str(batch_size)}_batchsize).json'\n",
    "one_hot_adv = F.softmax(torch.rand(20, embed_weights.shape[0], dtype=torch.float16).to(device=device), dim=1).to(embed_weights.dtype) # type: ignore\n",
    "one_hot_adv.requires_grad_() \n",
    "# Use this masked_one_hot_adv ONLY for discretization\n",
    "effective_adv_one_hot = one_hot_adv.clone()\n",
    "max_values = torch.max(get_masked_one_hot_adv(one_hot_adv), dim=1)\n",
    "adv_token_ids = max_values.indices \n",
    "# Initialize the optimizer\n",
    "optimizer = EGDwithAdamOptimizer([one_hot_adv], lr=step_size)\n",
    "# Initialize the learning_rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=50)\n",
    "# Specify the filename\n",
    "csv_filename = f'{directories[0]}/stats_multiprompt_using_EGD({str(len(harmful_behaviors))}_behaviors)({str(num_steps)}_steps)({str(batch_size)}_batchsize).csv'        \n",
    "# Generate column names\n",
    "column_names = ['epoch', 'learning_rate', \n",
    "                'entropy_term', 'kl_divergence_term', \n",
    "                'continuous_loss','discrete_loss'] \n",
    "# Adding 'max_1' to 'max_20' column names using a loop\n",
    "for i in range(1, 21):\n",
    "    column_names.append(f'max_{i}')\n",
    "for i in range(1, 21):\n",
    "    column_names.append(f'token_id_{i}')\n",
    "# Create an empty DataFrame\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "best_discrete_loss = np.inf\n",
    "best_discrete_loss_epoch = 0\n",
    "\n",
    "\n",
    "for epoch_no in tqdm(range(num_steps)):\n",
    "    # Shuffle indices each epoch\n",
    "    indices = np.random.permutation(len(harmful_behaviors))\n",
    "\n",
    "    # Annealing coefficient\n",
    "    reg_coefficient = initial_coefficient * (final_coefficient / initial_coefficient) ** (epoch_no / (num_steps - 1))\n",
    "    eps = 1e-12\n",
    "\n",
    "    # Track per-epoch metrics\n",
    "    epoch_continuous_losses = []\n",
    "    epoch_discrete_losses = []\n",
    "    epoch_entropy_terms = []\n",
    "    epoch_kl_terms = []\n",
    "\n",
    "    for batch_start in range(0, len(indices), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_ids = indices[batch_start:batch_start+batch_size]\n",
    "\n",
    "        # Compute entropy + KL once per batch\n",
    "        log_one_hot = torch.log(one_hot_adv.to(dtype=torch.float32) + eps)\n",
    "        entropy_term = -one_hot_adv * (log_one_hot - 1)\n",
    "        entropy_term = entropy_term.sum() * reg_coefficient\n",
    "\n",
    "        kl_divergence_term = -torch.log(torch.max(one_hot_adv, dim=1).values + eps).sum()\n",
    "        kl_divergence_term *= reg_coefficient\n",
    "\n",
    "        # Record for epoch average\n",
    "        epoch_entropy_terms.append(entropy_term.item())\n",
    "        epoch_kl_terms.append(kl_divergence_term.item())\n",
    "        \n",
    "        masked_one_hot_adv = get_masked_one_hot_adv(one_hot_adv)\n",
    "        adv_token_ids = masked_one_hot_adv.argmax(dim=1)\n",
    "        one_hot_discrete = F.one_hot(adv_token_ids, num_classes=embed_weights.shape[0]).to(embed_weights.dtype)\n",
    "\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for idx in batch_ids:\n",
    "            user_tokens = user_prompt_tokens_list[idx]\n",
    "            target_tokens = target_tokens_list[idx]\n",
    "\n",
    "            _, emb_user = create_one_hot_and_embeddings(user_tokens, embed_weights, device=device)\n",
    "            _, emb_target = create_one_hot_and_embeddings(target_tokens, embed_weights, device=device)\n",
    "            one_hot_target, _ = create_one_hot_and_embeddings(target_tokens, embed_weights, device=device)\n",
    "\n",
    "            emb_adv = (one_hot_adv @ embed_weights).unsqueeze(0)\n",
    "            emb_adv_discrete = (one_hot_discrete @ embed_weights).unsqueeze(0)\n",
    "\n",
    "            ce_loss, _ = calc_loss(model, emb_user, emb_adv, emb_target, one_hot_target)\n",
    "            disc_loss, _ = calc_loss(model, emb_user, emb_adv_discrete, emb_target, one_hot_target)\n",
    "\n",
    "            regularized_loss = ce_loss - entropy_term + kl_divergence_term\n",
    "            total_loss += regularized_loss\n",
    "\n",
    "            epoch_continuous_losses.append(ce_loss.item())\n",
    "            epoch_discrete_losses.append(disc_loss.item())\n",
    "\n",
    "        total_loss/=len(batch_ids)\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_([one_hot_adv], max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    mean_continuous_loss = np.mean(epoch_continuous_losses)\n",
    "    mean_discrete_loss = np.mean(epoch_discrete_losses)\n",
    "    mean_entropy = np.mean(epoch_entropy_terms)\n",
    "    mean_kl = np.mean(epoch_kl_terms)\n",
    "\n",
    "    if mean_discrete_loss < best_discrete_loss:\n",
    "        best_discrete_loss = mean_discrete_loss\n",
    "        best_discrete_loss_epoch = epoch_no\n",
    "        effective_adv_one_hot = one_hot_discrete\n",
    "\n",
    "    scheduler.step(mean_continuous_loss)\n",
    "\n",
    "    # Dump Ouput values to a CSV file\n",
    "    # Convert max_values to a NumPy array\n",
    "    max_values_array = max_values.values.detach().cpu().numpy()\n",
    "    token_ids_array = adv_token_ids.detach().cpu().numpy()\n",
    "    # Get the scheduler's state and learning_rate\n",
    "    # Access the current learning rate directly from the optimizer's parameter group\n",
    "    scheduler_lr = optimizer.param_groups[0]['lr']  # Get the learning rate of the first parameter group\n",
    "    # Create the Initial array       \n",
    "    prepend_array = np.array([epoch_no, scheduler_lr,\n",
    "                                mean_entropy, mean_kl,\n",
    "                                mean_continuous_loss, mean_discrete_loss]) \n",
    "    \n",
    "    # Concatenate the arrays\n",
    "    row = np.concatenate((prepend_array, max_values_array, token_ids_array))\n",
    "    new_row = pd.Series(row, index=df.columns)\n",
    "    df = pd.concat([df, new_row.to_frame().T], ignore_index=True)\n",
    "    \n",
    "    # Save every 10 epochs\n",
    "    if (epoch_no + 1) % 10 == 0:\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "\n",
    "# End of optimizations\n",
    "# Write to CSV file\n",
    "df.to_csv(csv_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Token and Output Generation Step #########\n",
    "# for i, row in enumerate(harmful_behaviors):\n",
    "for i, row in tqdm(enumerate(harmful_behaviors), desc=\"Generating outputs\", leave=False):\n",
    "    user_prompt, target = row\n",
    "    user_prompt_tokens = get_tokens(user_prompt, tokenizer=tokenizer, device=device)    \n",
    "    target_tokens = get_tokens(target, tokenizer=tokenizer, device=device)[1:] \n",
    "    # Get one_hot encodings and embedding vectors for the user prompts and targets \n",
    "    one_hot_inputs, embeddings_user = create_one_hot_and_embeddings(user_prompt_tokens, embed_weights, device=device)\n",
    "    one_hot_target, embeddings_target = create_one_hot_and_embeddings(target_tokens, embed_weights, device=device)\n",
    "    inputs_token_ids = one_hot_inputs.argmax(dim=1)\n",
    "    adv_token_ids = effective_adv_one_hot.argmax(dim=1)\n",
    "    adv_suffix_list = str(adv_token_ids.cpu().numpy().tolist())\n",
    "    adv_suffix_string = tokenizer.decode(adv_token_ids.cpu().numpy())\n",
    "    final_string_ids = torch.hstack([inputs_token_ids, adv_token_ids])\n",
    "    # outputs = []\n",
    "    generation_loop = range(1)\n",
    "    import warnings\n",
    "    # Suppress specific warnings\n",
    "    warnings.filterwarnings(\"ignore\", message=\".*`do_sample` is set to `False`. However, `temperature` is set to.*\")\n",
    "    warnings.filterwarnings(\"ignore\", message=\".*`do_sample` is set to `False`. However, `top_p` is set to.*\")\n",
    "    ######## Discrete tokens for Output Generation ########\n",
    "    # for loop in tqdm(generation_loop, desc=\"Generating outputs\", leave=False):\n",
    "    generated_output = model.generate(final_string_ids.unsqueeze(0), \n",
    "                                        max_length=num_tokens, \n",
    "                                        pad_token_id=tokenizer.pad_token_id,\n",
    "                                        do_sample=False)\n",
    "    generated_output_string = tokenizer.decode(generated_output[0][:].cpu().numpy(), skip_special_tokens=True).strip()\n",
    "    # outputs.append(generated_output_string)\n",
    "    iteration_result = {\n",
    "        \"harmful-behaviour\": user_prompt,\n",
    "        \"target\": target,\n",
    "        \"suffix_token_ids\": adv_suffix_list,\n",
    "        \"suffix_string\": adv_suffix_string,\n",
    "        \"best_disc_loss\":best_discrete_loss,\n",
    "        \"epch_at_best_disc_loss\": best_discrete_loss_epoch,\n",
    "        \"outputs\": generated_output_string\n",
    "    }\n",
    "    optimization_results.append(iteration_result)\n",
    "\n",
    "    # Update the JSON File\n",
    "    with open(json_filename, \"w\") as f:\n",
    "        json.dump(\n",
    "            optimization_results,\n",
    "            f,\n",
    "            indent=4,  # Keep structure readable\n",
    "            ensure_ascii=False  # Do this to Handle non-ASCII chars properly; If there is any\n",
    "        )\n",
    "\n",
    "    ##########################################################################################\n",
    "    # Create and Update a JSONL file (required for running the parse_results.ipynb script) ##\n",
    "    # output_file = directories[1]+\"/EGD_with_Adam_\"+model_name+\"(\"+str(len(harmful_behaviors))+\"_behaviors)(\"+str(num_steps)+\"_steps).jsonl\"\n",
    "    output_file = f'{directories[1]}/outputs_multiprompt_using_EGD({str(len(harmful_behaviors))}_behaviors)({str(num_steps)}_steps)({str(batch_size)}_batchsize).jsonl'\n",
    "    from behavior import Behavior\n",
    "    behavior = Behavior(user_prompt, adv_suffix_string, generated_output_string, \"\", \"\")\n",
    "\n",
    "    with open(output_file, 'a') as f:\n",
    "        f.write(json.dumps(behavior.to_dict()) + '\\n')\n",
    "    f.close()  \n",
    "    ## Create and Update a JSONL file (required for running the parse_results.ipynb script) ##\n",
    "    ########################################################################################## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the one_hot encodings using Gradient Descent.\n",
    "from math import *\n",
    "import json \n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "num_steps = 200\n",
    "step_size = 0.1\n",
    "# Fetch the Model's weights\n",
    "embed_weights = get_embedding_matrix(model)\n",
    "# reader = [[user_prompt, target]]\n",
    "optimization_results = []\n",
    "# Set your regularization parameter\n",
    "initial_coefficient = 1e-5\n",
    "final_coefficient = 1e-3\n",
    "\n",
    "directories = [f'./Multi-Prompt/CSV_Files/{model_name}/{dataset_name}',    # 0\n",
    "            f'./Multi-Prompt/JSON_Files/{model_name}/{dataset_name}']      # 1\n",
    "for directory in directories:\n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory '{directory}' created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory}' already exists.\")\n",
    "\n",
    "user_prompt_tokens_list =list()\n",
    "target_tokens_list = list()\n",
    "for i, row in enumerate(harmful_behaviors):\n",
    "    user_prompt, target = row\n",
    "    user_prompt_tokens_list.append(get_tokens(user_prompt, tokenizer=tokenizer, device=device) )   \n",
    "    target_tokens_list.append(get_tokens(target, tokenizer=tokenizer, device=device)[1:] )\n",
    "    \n",
    "# JSON file to dump the model generated outputs \n",
    "json_filename = directories[1]+\"/output_EGD_with_Adam_Optimizer(\"+str(len(harmful_behaviors))+\"_behaviors)(\"+str(num_steps)+\"_steps).json\"\n",
    "one_hot_adv = F.softmax(torch.rand(20, embed_weights.shape[0], dtype=torch.float16).to(device=device), dim=1).to(embed_weights.dtype) # type: ignore\n",
    "one_hot_adv.requires_grad_() \n",
    "# Use this masked_one_hot_adv ONLY for discretization\n",
    "effective_adv_one_hot = one_hot_adv.clone()\n",
    "max_values = torch.max(get_masked_one_hot_adv(one_hot_adv), dim=1)\n",
    "adv_token_ids = max_values.indices \n",
    "# Initialize the optimizer\n",
    "optimizer = EGDwithAdamOptimizer([one_hot_adv], lr=step_size)\n",
    "# Initialize the learning_rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=50)\n",
    "# Specify the filename\n",
    "csv_filename = directories[0]+'/stats_EGD_with_Adam_Optimizer('+str(len(harmful_behaviors))+\"_behaviors)(\"+str(num_steps)+'_steps).csv'        \n",
    "# Generate column names\n",
    "column_names = ['epoch', 'learning_rate', \n",
    "                'entropy_term', 'kl_divergence_term', \n",
    "                'continuous_loss','discrete_loss'] \n",
    "# Adding 'max_1' to 'max_20' column names using a loop\n",
    "for i in range(1, 21):\n",
    "    column_names.append(f'max_{i}')\n",
    "for i in range(1, 21):\n",
    "    column_names.append(f'token_id_{i}')\n",
    "# Create an empty DataFrame\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "best_discrete_loss = np.inf\n",
    "best_discrete_loss_epoch = 0\n",
    "\n",
    "for epoch_no in tqdm(range(num_steps)):\n",
    "    optimizer.zero_grad()\n",
    "    continuous_losses = np.zeros(len(harmful_behaviors))\n",
    "    discrete_losses = np.zeros(len(harmful_behaviors))\n",
    "    total_loss = 0.0 \n",
    "    # Calculate the annealed coefficient, ðœ–; Use Exponential Scheduling\n",
    "    reg_coefficient = initial_coefficient * (final_coefficient / initial_coefficient) ** (epoch_no / (num_steps - 1)) \n",
    "    # Calculate H(X) = âˆ’ âˆ‘_{i=1}^{L} âˆ‘_{j=1}^{|T|} X_{ij} (log X_{ij} âˆ’1)\n",
    "    # Adding a small epsilon to avoid log(0) which is undefined\n",
    "    eps = 1e-12\n",
    "    one_hot_adv_float32 = one_hot_adv.to(dtype=torch.float32)\n",
    "    log_one_hot = torch.log(one_hot_adv_float32 + eps)\n",
    "    # Compute the modified entropy\n",
    "    entropy_per_row = -one_hot_adv_float32 * (log_one_hot - 1)\n",
    "    entropy_term = entropy_per_row.sum()\n",
    "    entropy_term *= reg_coefficient \n",
    "    # Take the Negative log of the highest probability in each row\n",
    "    kl_divergence_term = -torch.log(torch.max(one_hot_adv, dim=1).values + eps).sum()\n",
    "    kl_divergence_term *=reg_coefficient\n",
    "    # # Discretization part; Do it once in every epoch\n",
    "    masked_one_hot_adv = get_masked_one_hot_adv(one_hot_adv)\n",
    "    # Use this masked_one_hot_adv ONLY for discretization\n",
    "    max_values = torch.max(masked_one_hot_adv, dim=1)\n",
    "    adv_token_ids = max_values.indices\n",
    "    one_hot_discrete = torch.zeros(\n",
    "        adv_token_ids.shape[0], embed_weights.shape[0], device=device, dtype=embed_weights.dtype # type: ignore\n",
    "    )\n",
    "    one_hot_discrete.scatter_(\n",
    "        1,\n",
    "        adv_token_ids.unsqueeze(1),\n",
    "        torch.ones(masked_one_hot_adv.shape[0], 1, device=device, dtype=embed_weights.dtype), # type: ignore\n",
    "    )\n",
    "    \n",
    "    for i, (user_prompt_tokens, target_tokens) in enumerate(zip(user_prompt_tokens_list, target_tokens_list)):\n",
    "        # Get one_hot encodings and embedding vectors for the user prompts and targets \n",
    "        one_hot_inputs, embeddings_user = create_one_hot_and_embeddings(user_prompt_tokens, embed_weights, device=device)\n",
    "        one_hot_target, embeddings_target = create_one_hot_and_embeddings(target_tokens, embed_weights, device=device)\n",
    "        # Get the embedding vectors for the adversarial suffix\n",
    "        embeddings_adv = (one_hot_adv @ embed_weights).unsqueeze(0)\n",
    "        cross_entropy_loss, _ = calc_loss(model, embeddings_user, embeddings_adv, embeddings_target, one_hot_target)\n",
    "         # Regularized loss: F(X) - epsilon * H(X) + epsilon * KL-term\n",
    "        regularized_loss = cross_entropy_loss - entropy_term + kl_divergence_term\n",
    "        total_loss+=regularized_loss\n",
    "\n",
    "        # Keep track of continuous loss\n",
    "        continuous_loss = cross_entropy_loss.detach().cpu().item()\n",
    "        continuous_losses[i] = continuous_loss        \n",
    "        # Keep track of Discrete loss\n",
    "        embeddings_adv_discrete = (one_hot_discrete @ embed_weights).unsqueeze(0)\n",
    "        discrete_loss, _ = calc_loss(model, embeddings_user, embeddings_adv_discrete, embeddings_target, one_hot_target)\n",
    "        discrete_loss =  discrete_loss.detach().cpu().item()\n",
    "        discrete_losses[i] = discrete_loss\n",
    "    \n",
    "    mean_continuous_loss = np.mean(continuous_losses)\n",
    "    mean_discrete_loss = np.mean(discrete_losses)\n",
    "    # If loss improves, save it as x_best\n",
    "    if mean_discrete_loss < best_discrete_loss:\n",
    "        best_discrete_loss = mean_discrete_loss\n",
    "        best_discrete_loss_epoch = epoch_no\n",
    "        effective_adv_one_hot = one_hot_discrete\n",
    "    # Average total_loss before computing gradients\n",
    "    total_loss/=len(harmful_behaviors)\n",
    "    # Backpropagate the regularized loss\n",
    "    total_loss.backward() # type: ignore\n",
    "    # Clip the gradients(before update)\n",
    "    torch.nn.utils.clip_grad_norm_([one_hot_adv], max_norm=1.0) # type: ignore\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    # update scheduler\n",
    "    scheduler.step(mean_continuous_loss)\n",
    "\n",
    "    # Dump Ouput values to a CSV file\n",
    "    # Convert max_values to a NumPy array\n",
    "    max_values_array = max_values.values.detach().cpu().numpy()\n",
    "    token_ids_array = adv_token_ids.detach().cpu().numpy()\n",
    "    # Get the scheduler's state and learning_rate\n",
    "    # Access the current learning rate directly from the optimizer's parameter group\n",
    "    scheduler_lr = optimizer.param_groups[0]['lr']  # Get the learning rate of the first parameter group\n",
    "    # Create the Initial array       \n",
    "    prepend_array = np.array([epoch_no, scheduler_lr,\n",
    "                                entropy_term.detach().cpu().item(),\n",
    "                                kl_divergence_term.detach().cpu().item(),\n",
    "                                mean_continuous_loss, mean_discrete_loss]) \n",
    "    \n",
    "    # Concatenate the arrays\n",
    "    row = np.concatenate((prepend_array, max_values_array, token_ids_array))\n",
    "    new_row = pd.Series(row, index=df.columns)\n",
    "    df = pd.concat([df, new_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "# End of optimizations\n",
    "# Write to CSV file\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "\n",
    "######### Token and Output Generation Step #########\n",
    "for i, row in enumerate(harmful_behaviors):\n",
    "    user_prompt, target = row\n",
    "    user_prompt_tokens = get_tokens(user_prompt, tokenizer=tokenizer, device=device)    \n",
    "    target_tokens = get_tokens(target, tokenizer=tokenizer, device=device)[1:] \n",
    "    # Get one_hot encodings and embedding vectors for the user prompts and targets \n",
    "    one_hot_inputs, embeddings_user = create_one_hot_and_embeddings(user_prompt_tokens, embed_weights, device=device)\n",
    "    one_hot_target, embeddings_target = create_one_hot_and_embeddings(target_tokens, embed_weights, device=device)\n",
    "    inputs_token_ids = one_hot_inputs.argmax(dim=1)\n",
    "    adv_token_ids = effective_adv_one_hot.argmax(dim=1)\n",
    "    adv_suffix_list = str(adv_token_ids.cpu().numpy().tolist())\n",
    "    adv_suffix_string = tokenizer.decode(adv_token_ids.cpu().numpy())\n",
    "    final_string_ids = torch.hstack([inputs_token_ids, adv_token_ids])\n",
    "    outputs = []\n",
    "    generation_loop = range(1)\n",
    "    import warnings\n",
    "    # Suppress specific warnings\n",
    "    warnings.filterwarnings(\"ignore\", message=\".*`do_sample` is set to `False`. However, `temperature` is set to.*\")\n",
    "    warnings.filterwarnings(\"ignore\", message=\".*`do_sample` is set to `False`. However, `top_p` is set to.*\")\n",
    "    generated_output_string = ''\n",
    "    ######## Discrete tokens for Output Generation ########\n",
    "    for loop in tqdm(generation_loop, desc=\"Generating outputs\", leave=False):\n",
    "        generated_output = model.generate(final_string_ids.unsqueeze(0), \n",
    "                                            max_length=num_tokens, \n",
    "                                            pad_token_id=tokenizer.pad_token_id,\n",
    "                                            do_sample=False)\n",
    "        generated_output_string = tokenizer.decode(generated_output[0][:].cpu().numpy(), skip_special_tokens=True).strip()\n",
    "        outputs.append(generated_output_string)\n",
    "\n",
    "    iteration_result = {\n",
    "        \"harmful-behaviour\": user_prompt,\n",
    "        \"target\": target,\n",
    "        \"suffix_token_ids\": adv_suffix_list,\n",
    "        \"suffix_string\": adv_suffix_string,\n",
    "        \"best_disc_loss\":best_discrete_loss,\n",
    "        \"epch_at_best_disc_loss\": best_discrete_loss_epoch,\n",
    "        \"outputs\": outputs\n",
    "    }\n",
    "    optimization_results.append(iteration_result)\n",
    "\n",
    "    # Update the JSON File\n",
    "    with open(json_filename, \"w\") as f:\n",
    "        json.dump(\n",
    "            optimization_results,\n",
    "            f,\n",
    "            indent=4,  # Keep structure readable\n",
    "            ensure_ascii=False  # Do this to Handle non-ASCII chars properly; If there is any\n",
    "        )\n",
    "\n",
    "    ##########################################################################################\n",
    "    # Create and Update a JSONL file (required for running the parse_results.ipynb script) ##\n",
    "    output_file = directories[1]+\"/EGD_with_Adam_\"+model_name+\"(\"+str(len(harmful_behaviors))+\"_behaviors)(\"+str(num_steps)+\"_steps).jsonl\"\n",
    "    from behavior import Behavior\n",
    "    behavior = Behavior(user_prompt, adv_suffix_string, generated_output_string, \"\", \"\")\n",
    "\n",
    "    with open(output_file, 'a') as f:\n",
    "        f.write(json.dumps(behavior.to_dict()) + '\\n')\n",
    "    f.close()  \n",
    "    ## Create and Update a JSONL file (required for running the parse_results.ipynb script) ##\n",
    "    ########################################################################################## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the following directories if they do NOT exist\n",
    "# directories = [f'./Multi-Prompt/CSV_Files/{model_name}/{dataset_name}',    # 0\n",
    "#             f'./Multi-Prompt/JSON_Files/{model_name}/{dataset_name}']      # 1\n",
    "# for directory in directories:\n",
    "#     # Create the directory if it doesn't exist\n",
    "#     if not os.path.exists(directory):\n",
    "#         os.makedirs(directory)\n",
    "#         print(f\"Directory '{directory}' created.\")\n",
    "#     else:\n",
    "#         print(f\"Directory '{directory}' already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# # Suppress specific warnings\n",
    "# warnings.filterwarnings(\"ignore\", message=\".*`do_sample` is set to `False`. However, `temperature` is set to.*\")\n",
    "# warnings.filterwarnings(\"ignore\", message=\".*`do_sample` is set to `False`. However, `top_p` is set to.*\")\n",
    "\n",
    "# def universal_suffix_attack_fixed(\n",
    "#     model,\n",
    "#     tokenizer,\n",
    "#     harmful_behaviors: List[Tuple[str, str]],\n",
    "#     embed_weights: torch.Tensor,\n",
    "#     device: str,\n",
    "#     model_name: str,\n",
    "#     dataset_name: str,\n",
    "#     suffix_len: int = 20,\n",
    "#     num_steps: int = 200,\n",
    "#     step_size: float = 0.1,\n",
    "#     eps: float = 1e-12,\n",
    "#     initial_coefficient: float = 1e-5,\n",
    "#     final_coefficient: float = 1e-3,\n",
    "#     Optimizer = torch.optim.Adam\n",
    "# ):\n",
    "#     # CSV file to dump the optimization results \n",
    "#     csv_filename = directories[0]+'/stats_EGD_with_Adam('+str(len(harmful_behaviors))+\"_behaviors)(\"+str(num_steps)+\"_steps).csv\"      \n",
    "    \n",
    "#     # Initialize one_hot_adv\n",
    "#     one_hot_adv = F.softmax(torch.rand(suffix_len, embed_weights.shape[0], dtype=torch.float32, device=device), dim=1)\n",
    "#     one_hot_adv.requires_grad_()\n",
    "#     # Initialize some values\n",
    "#     effective_adv_one_hot = torch.zeros_like(one_hot_adv)\n",
    "#     max_values = torch.max(get_masked_one_hot_adv(effective_adv_one_hot), dim=1)\n",
    "#     adv_token_ids = max_values.indices\n",
    "\n",
    "#     # Optimizer and scheduler\n",
    "#     optimizer = Optimizer([one_hot_adv], lr=step_size)\n",
    "#     # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=50)\n",
    "#     scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_steps)\n",
    "\n",
    "#     # Generate column names\n",
    "#     column_names = ['epoch', 'learning_rate', \n",
    "#                     'entropy_term', 'kl_divergence_term', \n",
    "#                     'continuous_loss','discrete_loss'] \n",
    "#     # Adding 'max_1' to 'max_20' column names using a loop\n",
    "#     column_names.extend([f'max_{i}' for i in range(1, suffix_len + 1)])\n",
    "#     column_names.extend([f'token_id_{i}' for i in range(1, suffix_len+1)])\n",
    "#     # Create an empty DataFrame\n",
    "#     df = pd.DataFrame(columns=column_names)\n",
    "#     # Keep Track of discrete losses\n",
    "#     best_disc_loss = np.inf\n",
    "#     best_loss_at_epoch = 0\n",
    "\n",
    "#     # Main loop\n",
    "#     for epoch_no in tqdm(range(num_steps), desc=f'Optimizing Universal Suffix â€” {model_name}, {dataset_name}'):\n",
    "#         optimizer.zero_grad()\n",
    "#         total_loss = None\n",
    "#         continuous_losses = np.zeros(len(harmful_behaviors))\n",
    "#         discrete_losses = np.zeros(len(harmful_behaviors))\n",
    "#         accumulated_grads = torch.zeros_like(one_hot_adv)\n",
    "#         # Calculate the regularization coefficient ðœ–, using Exponential Annealing\n",
    "#         reg_coefficient = initial_coefficient * (final_coefficient / initial_coefficient) ** (epoch_no / (num_steps - 1))\n",
    "\n",
    "#         # for i, (user_tokens, target_tokens) in enumerate(zip(user_prompt_tokens_list, target_tokens_list)):\n",
    "#         for i, row in enumerate(harmful_behaviors):\n",
    "#             # Get Tokens\n",
    "#             user_prompt, target  = row[0], row[1]\n",
    "#             user_tokens = get_tokens(user_prompt, tokenizer=tokenizer, device=device)\n",
    "#             target_tokens = get_tokens(target, tokenizer=tokenizer, device=device)[1:]\n",
    "#             # Get Embeddings and compute Cross-Entropy loss\n",
    "#             _, embeddings_user = create_one_hot_and_embeddings(user_tokens, embed_weights, device=device)\n",
    "#             one_hot_target, embeddings_target = create_one_hot_and_embeddings(target_tokens, embed_weights, device=device)\n",
    "#             embeddings_adv = (one_hot_adv.to(dtype=torch.float16) @ embed_weights).unsqueeze(0)\n",
    "#             cross_entropy_loss, _ = calc_loss(model, embeddings_user, embeddings_adv, embeddings_target, one_hot_target)\n",
    "#             continuous_losses[i] = cross_entropy_loss.detach().cpu().item()\n",
    "\n",
    "#             # Regularization terms (computed per behavior!)\n",
    "#             # Compute Entropy\n",
    "#             log_one_hot = torch.log(one_hot_adv + eps)\n",
    "#             entropy_term = -(one_hot_adv * (log_one_hot - 1)).sum() * reg_coefficient\n",
    "#             # Compute KL-divergence term\n",
    "#             kl_divergence_term = -torch.log(torch.max(one_hot_adv, dim=1).values + eps).sum() * reg_coefficient\n",
    "\n",
    "#             # Final regularized loss\n",
    "#             regularized_loss = cross_entropy_loss - entropy_term + kl_divergence_term\n",
    "#             # Backprop\n",
    "#             regularized_loss.backward(retain_graph=True)\n",
    "#             accumulated_grads += one_hot_adv.grad.clone()\n",
    "#             one_hot_adv.grad.zero_()\n",
    "\n",
    "#             # # Accumulate total loss\n",
    "#             # total_loss = regularized_loss if i==0 else total_loss+regularized_loss\n",
    "\n",
    "#             # Discrete tracking\n",
    "#             masked_one_hot_adv = get_masked_one_hot_adv(one_hot_adv)\n",
    "#             max_values = torch.max(masked_one_hot_adv, dim=1)\n",
    "#             adv_token_ids = max_values.indices\n",
    "\n",
    "#             one_hot_discrete = torch.zeros_like(one_hot_adv)\n",
    "#             one_hot_discrete.scatter_(1, adv_token_ids.unsqueeze(1), 1.0)\n",
    "\n",
    "#             embeddings_adv_discrete = (one_hot_discrete.to(dtype=torch.float16) @ embed_weights).unsqueeze(0)\n",
    "#             discrete_loss, _ = calc_loss(model, embeddings_user, embeddings_adv_discrete, embeddings_target, one_hot_target)\n",
    "#             discrete_loss = discrete_loss.detach().cpu().item()\n",
    "#             discrete_losses[i] = discrete_loss\n",
    "\n",
    "#             # Track best discrete suffix\n",
    "#             if discrete_loss < best_disc_loss:\n",
    "#                 best_disc_loss = discrete_loss\n",
    "#                 best_loss_at_epoch = epoch_no\n",
    "#                 effective_adv_one_hot = one_hot_discrete.clone()\n",
    "\n",
    "#         # Compute mean continuous and discrete losses\n",
    "#         mean_continuous_loss = np.mean(continuous_losses)\n",
    "#         mean_discrete_loss = np.mean(discrete_losses)\n",
    "\n",
    "#         # Final backward + optimizer step\n",
    "#         # total_loss /= len(harmful_behaviors) # type: ignore\n",
    "#         # total_loss.backward()\n",
    "#         # Apply mean gradient, no normalization\n",
    "#         accumulated_grads /= len(harmful_behaviors)\n",
    "#         one_hot_adv.grad = accumulated_grads\n",
    "#         # Gradient clipping is not necessary for EGD\n",
    "#         # torch.nn.utils.clip_grad_norm_([one_hot_adv], max_norm=1.0) # type: ignore\n",
    "#         # update parameters\n",
    "#         optimizer.step()\n",
    "#         # update scheduler\n",
    "#         scheduler.step(mean_continuous_loss)\n",
    "#         # Dump Ouput values to a CSV file\n",
    "#         # Convert max_values to a NumPy array\n",
    "#         max_values_array = max_values.values.detach().cpu().numpy()\n",
    "#         token_ids_array = adv_token_ids.detach().cpu().numpy()\n",
    "#         # Get the scheduler's state and learning_rate\n",
    "#         # Access the current learning rate directly from the optimizer's parameter group\n",
    "#         scheduler_lr = optimizer.param_groups[0]['lr']  # Get the learning rate of the first parameter group\n",
    "#         # Create the Initial array       \n",
    "#         prepend_array = np.array([epoch_no, scheduler_lr,\n",
    "#                                 entropy_term.detach().cpu().item(),  # type: ignore\n",
    "#                                 kl_divergence_term.detach().cpu().item(), # type: ignore\n",
    "#                                 mean_continuous_loss, mean_discrete_loss]) \n",
    "        \n",
    "#         # Concatenate the arrays\n",
    "#         row = np.concatenate((prepend_array, max_values_array, token_ids_array))\n",
    "#         new_row = pd.Series(row, index=df.columns)\n",
    "#         df = pd.concat([df, new_row.to_frame().T], ignore_index=True)    \n",
    "#     # End for loop                             \n",
    "#     # Write to CSV file\n",
    "#     df.to_csv(csv_filename, index=False)\n",
    "#     return effective_adv_one_hot, best_disc_loss, best_loss_at_epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fetch the Model's weights\n",
    "# embed_weights = get_embedding_matrix(model)\n",
    "# num_steps = 200\n",
    "\n",
    "# effective_adv_one_hot, best_disc_loss, best_loss_at_epoch = universal_suffix_attack_fixed(\n",
    "#     model = model,\n",
    "#     tokenizer = tokenizer,\n",
    "#     harmful_behaviors= harmful_behaviors, # type: ignore\n",
    "#     embed_weights= embed_weights, # type: ignore\n",
    "#     device= device, # type: ignore\n",
    "#     model_name= model_name,\n",
    "#     dataset_name= dataset_name,\n",
    "#     num_steps= num_steps,\n",
    "#     Optimizer= EGDwithAdamOptimizer) # type: ignore\n",
    "\n",
    "# # JSON file to dump the  outputs \n",
    "# json_file_path = directories[1]+\"/output_EGD_with_Adam(\"+str(len(harmful_behaviors))+\"_behaviors)(\"+str(num_steps)+\"_steps).json\"\n",
    "\n",
    "# optimization_results = list()\n",
    "# # Generate the model's output using one_hot_adv\n",
    "# for row in tqdm(harmful_behaviors, desc=\"Generating Outputs\"):\n",
    "#     iteration_result = {}\n",
    "#     user_prompt, target = row\n",
    "#     # print(user_prompt)\n",
    "#     # target = unsafe_target\n",
    "#     user_prompt_tokens = get_tokens(user_prompt, tokenizer=tokenizer, device=device)    \n",
    "#     target_tokens = get_tokens(target, tokenizer=tokenizer, device=device)[1:]\n",
    "#     # Initialize one_hot encodings and embedding vectors for the user prompts and targets \n",
    "#     one_hot_inputs, _ = create_one_hot_and_embeddings(user_prompt_tokens, embed_weights, device=device)\n",
    "#     # one_hot_target, embeddings_target = create_one_hot_and_embeddings(target_tokens, embed_weights, device=device)\n",
    "#     # Token and Output Generation Step\n",
    "#     inputs_token_ids = one_hot_inputs.argmax(dim=1)\n",
    "#     adv_token_ids = effective_adv_one_hot.argmax(dim=1)\n",
    "#     adv_suffix_list = str(adv_token_ids.cpu().numpy().tolist())\n",
    "#     adv_suffix_string = tokenizer.decode(adv_token_ids.cpu().numpy())\n",
    "#     final_string_ids = torch.hstack([inputs_token_ids, adv_token_ids])\n",
    "#     outputs = []\n",
    "#     generation_loop = range(1)\n",
    "    \n",
    "#     ######## Discrete tokens for Output Generation ########\n",
    "#     for loop in tqdm(generation_loop, desc=\"Generating outputs\", leave=False):\n",
    "#         generated_output = model.generate(final_string_ids.unsqueeze(0), \n",
    "#                                         max_length=num_tokens, \n",
    "#                                         pad_token_id=tokenizer.pad_token_id,\n",
    "#                                         do_sample=False)\n",
    "#         generated_output_string = tokenizer.decode(generated_output[0][:].cpu().numpy(), skip_special_tokens=True).strip()\n",
    "#         outputs.append(generated_output_string)\n",
    "    \n",
    "#         iteration_result = {\n",
    "#             \"harmful-behaviour\": user_prompt,\n",
    "#             \"target\": target,\n",
    "#             \"suffix_token_ids\": adv_suffix_list,\n",
    "#             \"suffix_string\": adv_suffix_string,\n",
    "#             # \"epoch_no\": epoch_no,\n",
    "#             # \"continuous_loss\": continuous_loss,\n",
    "#             # \"discrete_loss\": discrete_loss,\n",
    "#             \"best_disc_loss\":best_disc_loss,\n",
    "#             \"epch_at_best_disc_loss\": best_loss_at_epoch,\n",
    "#             \"outputs\": outputs\n",
    "#         }\n",
    "#         optimization_results.append(iteration_result)\n",
    "\n",
    "#         # Update the JSON File\n",
    "#         with open(json_file_path, \"w\") as f:\n",
    "#             json.dump(\n",
    "#                 optimization_results,\n",
    "#                 f,\n",
    "#                 indent=4,  # Keep structure readable\n",
    "#                 ensure_ascii=False  # Do this to Handle non-ASCII chars properly; If there is any\n",
    "#             )\n",
    "\n",
    "#         ##########################################################################################\n",
    "#         ## Create and Update a JSONL file (required for running the parse_results.ipynb script) ##\n",
    "#         # output_file = directories[1]+\"/EGD_with_Adam_\"+model_name+\"(\"+str(len(harmful_behaviors))+\"_behaviors)(\"+str(num_steps)+\"_steps).jsonl\"\n",
    "#         # from behavior import Behavior\n",
    "#         # behavior = Behavior(user_prompt, adv_suffix_string, generated_output_string, \"\", \"\")\n",
    "        \n",
    "#         # with open(output_file, 'a') as f:\n",
    "#         #     f.write(json.dumps(behavior.to_dict()) + '\\n')\n",
    "#         # f.close()  \n",
    "#         ## Create and Update a JSONL file (required for running the parse_results.ipynb script) ##\n",
    "#         ########################################################################################## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# # Suppress specific warnings\n",
    "# warnings.filterwarnings(\"ignore\", message=\".*`do_sample` is set to `False`. However, `temperature` is set to.*\")\n",
    "# warnings.filterwarnings(\"ignore\", message=\".*`do_sample` is set to `False`. However, `top_p` is set to.*\")\n",
    "\n",
    "# def universal_suffix_attack(\n",
    "#     model,\n",
    "#     tokenizer,\n",
    "#     harmful_behaviors: List[Tuple[str, str]],\n",
    "#     embed_weights: torch.Tensor,\n",
    "#     device: str,\n",
    "#     model_name: str,\n",
    "#     dataset_name: str,\n",
    "#     suffix_len: int = 20,\n",
    "#     num_steps: int = 200,\n",
    "#     step_size: float = 1e-2,\n",
    "#     initial_coefficient: float = 1e-5,\n",
    "#     final_coefficient: float = 1e-3,\n",
    "#     Optimizer = torch.optim.Adam  # Replace with your custom optimizer class if needed\n",
    "# ):\n",
    "\n",
    "#     user_prompt_tokens_list = list()\n",
    "#     target_tokens_list = list()\n",
    "#     for user_prompt, target in harmful_behaviors:\n",
    "#         user_tokens = get_tokens(user_prompt, tokenizer=tokenizer, device=device)\n",
    "#         target_tokens = get_tokens(target, tokenizer=tokenizer, device=device)[1:]  # skip BOS if needed\n",
    "#         user_prompt_tokens_list.append(user_tokens)\n",
    "#         target_tokens_list.append(target_tokens)\n",
    "\n",
    "#     best_disc_loss = np.inf\n",
    "#     best_loss_at_epoch = 0\n",
    "#     # Random Initialization of the one_hot_adv \n",
    "#     one_hot_adv = F.softmax(torch.rand(20, embed_weights.shape[0], dtype=torch.float16, device=device), dim=1).to(embed_weights.dtype)\n",
    "#     one_hot_adv.requires_grad_() \n",
    "#     # Initialize some values\n",
    "#     effective_adv_one_hot = torch.zeros_like(one_hot_adv)\n",
    "#     max_values = torch.max(effective_adv_one_hot, dim=1)\n",
    "#     adv_token_ids = max_values.indices\n",
    "#     # Initialize the optimizer\n",
    "#     optimizer = Optimizer([one_hot_adv], lr=step_size)\n",
    "#     # Initialize the learning_rate scheduler\n",
    "#     scheduler_cycle = 0\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=50)\n",
    "\n",
    "#     # Generate column names\n",
    "#     column_names = ['epoch', 'cycle', 'learning_rate', \n",
    "#                     'entropy_term', 'kl_divergence_term', \n",
    "#                     'continuous_loss','discrete_loss'] \n",
    "#     # Adding 'max_1' to 'max_20' column names using a loop\n",
    "#     column_names.extend([f'max_{i}' for i in range(1, suffix_len + 1)])\n",
    "#     column_names.extend([f'token_id_{i}' for i in range(1, suffix_len+1)])\n",
    "#     # Create an empty DataFrame\n",
    "#     df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "#     for epoch_no in tqdm(range(num_steps), desc=f'Optimizing prompts â€” model: {model_name}, dataset: {dataset_name}'):\n",
    "#         optimizer.zero_grad()\n",
    "#         continuous_losses = np.zeros(len(harmful_behaviors)) # to compute avg_cont_loss for each epoch\n",
    "#         discrete_losses = np.zeros(len(harmful_behaviors)) # to compute avg_disc_loss for each epoch\n",
    "#         # accumulated_grads = torch.zeros_like(one_hot_adv)\n",
    "#         # total_loss = None\n",
    "\n",
    "#         ################# Usual entropy #################\n",
    "#         # # Calculate H(X) = âˆ’ âˆ‘_{i=1}^{L} âˆ‘_{j=1}^{|T|} X_{ij} (log X_{ij} âˆ’1)\n",
    "#         # Adding a small epsilon to avoid log(0) which is undefined\n",
    "#         eps = 1e-12\n",
    "#         one_hot_adv_float32 = one_hot_adv.to(dtype=torch.float32)\n",
    "#         log_one_hot = torch.log(one_hot_adv_float32 + eps)\n",
    "#         # Calculate the annealed coefficient ðœ–, using Exponential Scheduling\n",
    "#         reg_coefficient = initial_coefficient * (final_coefficient / initial_coefficient) ** (epoch_no / (num_steps - 1))   \n",
    "#         # Compute the modified entropy\n",
    "#         entropy_per_row = -one_hot_adv_float32 * (log_one_hot - 1)\n",
    "#         entropy_term = entropy_per_row.sum()        \n",
    "#         # Take the Negative log of the highest probability in each row\n",
    "#         kl_divergence_term = -torch.log(torch.max(one_hot_adv, dim=1).values + eps).sum()\n",
    "#         entropy_term *=reg_coefficient\n",
    "#         kl_divergence_term *=reg_coefficient\n",
    "\n",
    "#         for i, (user_tokens, target_tokens) in enumerate(zip(user_prompt_tokens_list, target_tokens_list)):\n",
    "#             # Get embedding vectors for the user prompts and targets\n",
    "#             _, embeddings_user = create_one_hot_and_embeddings(user_tokens, embed_weights, device=device)\n",
    "#             one_hot_target, embeddings_target = create_one_hot_and_embeddings(target_tokens, embed_weights, device=device)\n",
    "#             embeddings_adv = (one_hot_adv @ embed_weights).unsqueeze(0)\n",
    "#             cross_entropy_loss, _ = calc_loss(model, embeddings_user, embeddings_adv, embeddings_target, one_hot_target)\n",
    "#             continuous_losses[i] = cross_entropy_loss.detach().cpu().item()\n",
    "#             # Regularized loss: F(X) - epsilon * H(X) + epsilon * KL(P||Q)\n",
    "#             regularized_loss =  cross_entropy_loss - entropy_term + kl_divergence_term\n",
    "#             regularized_loss.backward()\n",
    "#             # if i==0:\n",
    "#             #     total_loss=regularized_loss\n",
    "#             # else: \n",
    "#             #     total_loss+=regularized_loss\n",
    "#             # # Backpropagate the regularized loss\n",
    "#             # total_loss.backward(retain_graph=True)\n",
    "#             # Discretization part\n",
    "#             masked_one_hot_adv = get_masked_one_hot_adv(one_hot_adv)\n",
    "#             # Use this masked_one_hot_adv ONLY for discretization\n",
    "#             max_values = torch.max(masked_one_hot_adv, dim=1)\n",
    "#             adv_token_ids = max_values.indices\n",
    "#             # adv_token_ids = one_hot_discrete.argmax(dim=1)\n",
    "#             one_hot_discrete = torch.zeros(\n",
    "#                 adv_token_ids.shape[0], embed_weights.shape[0], device=device, dtype=embed_weights.dtype\n",
    "#             )\n",
    "#             one_hot_discrete.scatter_(\n",
    "#                 1,\n",
    "#                 adv_token_ids.unsqueeze(1),\n",
    "#                 torch.ones(masked_one_hot_adv.shape[0], 1, device=device, dtype=embed_weights.dtype),\n",
    "#             )\n",
    "#             # Use one_hot_discrete to print Tokens\n",
    "#             # What other techniques Can we use here to discretize the one_hot encodings?\n",
    "#             # Use discrete tokens to calculate loss\n",
    "#             embeddings_adv_discrete = (one_hot_discrete @ embed_weights).unsqueeze(0)\n",
    "#             discrete_loss, _ = calc_loss(model, embeddings_user, embeddings_adv_discrete, embeddings_target, one_hot_target)\n",
    "#             # If loss improves, save it as x_best\n",
    "#             discrete_loss =  discrete_loss.detach().cpu().item()\n",
    "#             discrete_losses[i] = discrete_loss\n",
    "#             # cur_loss_list.append(cur_loss)\n",
    "#             if discrete_loss < best_disc_loss:\n",
    "#                 # print(f\"########## {discrete_loss} #########\")\n",
    "#                 best_disc_loss = discrete_loss\n",
    "#                 best_loss_at_epoch = epoch_no\n",
    "#                 effective_adv_one_hot = one_hot_discrete\n",
    "#             else :\n",
    "#                 pass\n",
    "#         # End for loop            \n",
    "#         # Average and backward once\n",
    "#         # total_loss /= len(continuous_losses) # type: ignore\n",
    "#         # total_loss.backward() # type: ignore\n",
    "\n",
    "#         # Clip and step\n",
    "#         torch.nn.utils.clip_grad_norm_([one_hot_adv], max_norm=1.0) # type: ignore\n",
    "#         optimizer.step()\n",
    "#         # accumulated_grads = accumulated_grads / len(continuous_losses)\n",
    "#         # accumulated_grads = F.normalize(accumulated_grads, p=2.0, dim=1)\n",
    "#         # one_hot_adv.grad = accumulated_grads\n",
    "#         # torch.nn.utils.clip_grad_norm_([one_hot_adv], max_norm=1.0) # type: ignore\n",
    "#         # # Update parameters\n",
    "#         # optimizer.step()\n",
    "        \n",
    "#         mean_continuous_loss = np.mean(continuous_losses)\n",
    "#         mean_discrete_loss = np.mean(discrete_losses)\n",
    "#         # update scheduler\n",
    "#         scheduler.step(mean_continuous_loss)\n",
    "#         # Dump Ouput values to a CSV file\n",
    "#         # Convert max_values to a NumPy array\n",
    "#         max_values_array = max_values.values.detach().cpu().numpy()\n",
    "#         token_ids_array = adv_token_ids.detach().cpu().numpy()\n",
    "#         # Get the scheduler's state and learning_rate\n",
    "#         # Access the current learning rate directly from the optimizer's parameter group\n",
    "#         scheduler_lr = optimizer.param_groups[0]['lr']  # Get the learning rate of the first parameter group\n",
    "#         # Create the Initial array       \n",
    "#         prepend_array = np.array([epoch_no, scheduler_cycle, scheduler_lr,\n",
    "#                                 entropy_term.detach().cpu().item(), \n",
    "#                                 kl_divergence_term.detach().cpu().item(),\n",
    "#                                 mean_continuous_loss, mean_discrete_loss]) \n",
    "        \n",
    "#         # Concatenate the arrays\n",
    "#         row = np.concatenate((prepend_array, max_values_array, token_ids_array))\n",
    "#         new_row = pd.Series(row, index=df.columns)\n",
    "#         df = pd.concat([df, new_row.to_frame().T], ignore_index=True)    \n",
    "#     # End for loop                             \n",
    "#     # Write to CSV file\n",
    "#     df.to_csv(csv_filename, index=False)\n",
    "#     return effective_adv_one_hot, best_disc_loss, best_loss_at_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Update the one_hot encodings using Gradient Descent.\n",
    "# from math import *\n",
    "# import json \n",
    "# import pandas as pd\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# # Fetch the Model's weights\n",
    "# embed_weights = get_embedding_matrix(model)\n",
    "# # reader = [[user_prompt, target]]\n",
    "# optimization_results = []\n",
    "# # Set your regularization parameter\n",
    "# initial_coefficient = 1e-5\n",
    "# final_coefficient = 1e-3\n",
    "\n",
    "\n",
    "# # Create the following directories if they do NOT exist\n",
    "# directories = [f'./Multi-Prompt/CSV_Files/{model_name}/{dataset_name}',       # 0\n",
    "#                f'./Multi-Prompt/JSON_Files/{model_name}/{dataset_name}']      # 1\n",
    "# for directory in directories:\n",
    "#     # Create the directory if it doesn't exist\n",
    "#     if not os.path.exists(directory):\n",
    "#         os.makedirs(directory)\n",
    "#         print(f\"Directory '{directory}' created.\")\n",
    "#     else:\n",
    "#         print(f\"Directory '{directory}' already exists.\")\n",
    "\n",
    "    \n",
    "# # JSON file to dump the model generated outputs \n",
    "# json_file_path = directories[1]+\"/output_EGD_with_Adam_Optimizer(\"+str(len(harmful_behaviors))+\"_behaviors)(\"+str(num_steps)+\"_steps).json\"\n",
    "\n",
    "# for row in tqdm(harmful_behaviors, desc=\"Optimizing prompts\"):\n",
    "#     iteration_result = {}\n",
    "#     user_prompt, target = row\n",
    "#     print(user_prompt)\n",
    "#     # target = unsafe_target\n",
    "#     user_prompt_tokens = get_tokens(user_prompt, tokenizer=tokenizer, device=device)    \n",
    "#     target_tokens = get_tokens(target, tokenizer=tokenizer, device=device)[1:]\n",
    "#     plotlosses = PlotLosses()\n",
    "#     plotlosses = PlotLosses(groups={'loss': ['continuous_loss', 'discrete_loss']})    \n",
    "#     target_tokens = get_tokens(target, tokenizer=tokenizer, device=device)[1:]\n",
    "\n",
    "#     # Initialize one_hot encodings and embedding vectors for the user prompts and targets \n",
    "#     one_hot_inputs, embeddings_user = create_one_hot_and_embeddings(user_prompt_tokens, embed_weights, device=device)\n",
    "#     one_hot_target, embeddings_target = create_one_hot_and_embeddings(target_tokens, embed_weights, device=device)\n",
    "#     best_disc_loss = np.inf\n",
    "#     best_loss_at_epoch = 0\n",
    "#     # Initialize one_hot_adv Randomly.\n",
    "#     # one_hot_adv = F.softmax(torch.rand(20, tokenizer.vocab_size, dtype=torch.float16).to(device=device), dim=1).to(embed_weights.dtype)   \n",
    "#     one_hot_adv = F.softmax(torch.rand(20, embed_weights.shape[0], dtype=torch.float16, device=device), dim=1).to(embed_weights.dtype)\n",
    "#     one_hot_adv.requires_grad_() \n",
    "#     # Initialize the optimizer\n",
    "#     optimizer = EGDwithAdamOptimizer([one_hot_adv], lr=step_size)\n",
    "#     # Initialize the learning_rate scheduler\n",
    "#     scheduler_cycle = 0\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=50)\n",
    "#     # Specify the filename\n",
    "#     last_three_words = lambda text: '_'.join(text.split()[-3:])\n",
    "#     first_three_words = lambda text: '_'.join(text.split()[0:3])\n",
    "#     csv_filename = directories[0]+'/output_EGD_with_Adam_Optimizer('+first_three_words(user_prompt)+\"..\"+last_three_words(user_prompt)+')('+str(num_steps)+'_steps).csv'        \n",
    "#     # Generate column names\n",
    "#     column_names = ['epoch', 'cycle', 'learning_rate', 'entropy_term', \n",
    "#                     'kl_divergence_term', \n",
    "#                     'continuous_loss','discrete_loss'] \n",
    "#     # Adding 'max_1' to 'max_20' column names using a loop\n",
    "#     for i in range(1, 21):\n",
    "#         column_names.append(f'max_{i}')\n",
    "#     for i in range(1, 21):\n",
    "#         column_names.append(f'token_id_{i}')\n",
    "#     # Create an empty DataFrame\n",
    "#     df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "#     # PHASE_2: bool=False\n",
    "#     BREAK_IT: bool=False\n",
    "\n",
    "#     for epoch_no in tqdm(range(num_steps)):\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         embeddings_adv = (one_hot_adv @ embed_weights).unsqueeze(0)\n",
    "#         cross_entropy_loss, _ = calc_loss(model, embeddings_user, embeddings_adv, embeddings_target, one_hot_target)\n",
    "#         continuous_loss = cross_entropy_loss.detach().cpu().item()\n",
    "#         # Break the loop if loss becomes \"NaN\"\n",
    "#         if math.isnan(continuous_loss):\n",
    "#             print(\"The value is NaN.\")\n",
    "#             BREAK_IT=True # Go to the Next Behavior\n",
    "\n",
    "#         # # Discretization part\n",
    "#         masked_one_hot_adv = get_masked_one_hot_adv(one_hot_adv)\n",
    "#         # Use this masked_one_hot_adv ONLY for discretization\n",
    "#         max_values = torch.max(masked_one_hot_adv, dim=1)\n",
    "#         adv_token_ids = max_values.indices\n",
    "#         # adv_token_ids = top_k_sampling(one_hot_adv, k=10).squeeze(dim=1)\n",
    "#         # tau = initial_tau * (final_tau / initial_tau) ** (epoch_no / (num_steps - 1))\n",
    "#         # one_hot_discrete = F.gumbel_softmax(one_hot_adv, tau=tau, hard=True)\n",
    "#         # adv_token_ids = one_hot_discrete.argmax(dim=1)\n",
    "#         one_hot_discrete = torch.zeros(\n",
    "#             adv_token_ids.shape[0], embed_weights.shape[0], device=device, dtype=embed_weights.dtype\n",
    "#         )\n",
    "#         one_hot_discrete.scatter_(\n",
    "#             1,\n",
    "#             adv_token_ids.unsqueeze(1),\n",
    "#             torch.ones(masked_one_hot_adv.shape[0], 1, device=device, dtype=embed_weights.dtype),\n",
    "#         )\n",
    "#         # Use one_hot_discrete to print Tokens\n",
    "#         # What other techniques Can we use here to discretize the one_hot encodings?\n",
    "#         # Use discrete tokens to calculate loss\n",
    "#         embeddings_adv_discrete = (one_hot_discrete @ embed_weights).unsqueeze(0)\n",
    "#         disc_loss, _ = calc_loss(model, embeddings_user, embeddings_adv_discrete, embeddings_target, one_hot_target)\n",
    "#         # If loss improves, save it as x_best\n",
    "#         discrete_loss =  disc_loss.detach().cpu().item()\n",
    "#         # cur_loss_list.append(cur_loss)\n",
    "#         if discrete_loss < best_disc_loss:\n",
    "#             # print(f\"########## {discrete_loss} #########\")\n",
    "#             best_disc_loss = discrete_loss\n",
    "#             best_loss_at_epoch = epoch_no\n",
    "#             effective_adv_embeddings = embeddings_adv_discrete\n",
    "#             effective_adv_one_hot = one_hot_discrete\n",
    "#         else :\n",
    "#             pass\n",
    "\n",
    "#         ################# Usual entropy #################\n",
    "#         # # Calculate H(X) = âˆ’ âˆ‘_{i=1}^{L} âˆ‘_{j=1}^{|T|} X_{ij} (log X_{ij} âˆ’1)\n",
    "#         # Adding a small epsilon to avoid log(0) which is undefined\n",
    "#         eps = 1e-12\n",
    "#         one_hot_adv_float32 = one_hot_adv.to(dtype=torch.float32)\n",
    "#         log_one_hot = torch.log(one_hot_adv_float32 + eps)\n",
    "#         # Compute the modified entropy\n",
    "#         entropy_per_row = -one_hot_adv_float32 * (log_one_hot - 1)\n",
    "#         entropy_term = entropy_per_row.sum()\n",
    "#         # Calculate the annealed coefficient, ðœ–\n",
    "#         # Use Exponential Scheduling\n",
    "#         reg_coefficient = initial_coefficient * (final_coefficient / initial_coefficient) ** (epoch_no / (num_steps - 1))   \n",
    "#         entropy_term *= reg_coefficient \n",
    "#         # Regularized loss: F(X) - epsilon * H(X)\n",
    "#         regularized_loss = cross_entropy_loss - entropy_term\n",
    "#         # Take the Negative log of the highest probability in each row\n",
    "#         kl_divergence_term = -torch.log(torch.max(one_hot_adv, dim=1).values + eps).sum()\n",
    "#         kl_divergence_term *=reg_coefficient\n",
    "#         regularized_loss +=kl_divergence_term\n",
    "\n",
    "#         # Backpropagate the regularized loss\n",
    "#         regularized_loss.backward()\n",
    "\n",
    "#         # Get the scheduler's state to get learning_rate\n",
    "#         scheduler_state = scheduler.state_dict()\n",
    "\n",
    "#         # Clip the gradients(before update)\n",
    "#         torch.nn.utils.clip_grad_norm_([one_hot_adv], max_norm=1.0)\n",
    "\n",
    "#         # update parameters\n",
    "#         optimizer.step()\n",
    "#         # update scheduler\n",
    "#         scheduler.step(continuous_loss)\n",
    "#         # # Reset the gradients; redundant after calling optimizer.zero_grad()\n",
    "#         # model.zero_grad()\n",
    "#         # one_hot_adv.grad.zero_()\n",
    "        \n",
    "\n",
    "#         # Dump Ouput values to a CSV file\n",
    "#         # Convert max_values to a NumPy array\n",
    "#         max_values_array = max_values.values.detach().cpu().numpy()\n",
    "#         token_ids_array = adv_token_ids.detach().cpu().numpy()\n",
    "#         # Get the scheduler's state and learning_rate\n",
    "#         # Access the current learning rate directly from the optimizer's parameter group\n",
    "#         scheduler_lr = optimizer.param_groups[0]['lr']  # Get the learning rate of the first parameter group\n",
    "#         # scheduler_lr = scheduler_state['_last_lr'][0]\n",
    "#         # Create the Initial array       \n",
    "#         prepend_array = np.array([epoch_no, scheduler_cycle, scheduler_lr,\n",
    "#                                   entropy_term.detach().cpu().item(), \n",
    "#                                   kl_divergence_term.detach().cpu().item(),\n",
    "#                                   continuous_loss, discrete_loss]) \n",
    "        \n",
    "#         # Concatenate the arrays\n",
    "#         row = np.concatenate((prepend_array, max_values_array, token_ids_array))\n",
    "#         new_row = pd.Series(row, index=df.columns)\n",
    "#         df = pd.concat([df, new_row.to_frame().T], ignore_index=True)\n",
    "#         # # Save log data to CSV file periodically\n",
    "#         # if epoch_no % 10 == 0:\n",
    "#         #     df.to_csv(csv_filename, index=False)\n",
    "#         # Something went wrong; so break it and go to the next behavior.\n",
    "#         if BREAK_IT==True:\n",
    "#             break\n",
    "#     # End of optimizations        \n",
    "#     # Write to CSV file\n",
    "#     df.to_csv(csv_filename, index=False)\n",
    "#     # Token and Output Generation Step\n",
    "#     inputs_token_ids = one_hot_inputs.argmax(dim=1)\n",
    "#     adv_token_ids = effective_adv_one_hot.argmax(dim=1)\n",
    "#     adv_suffix_list = str(adv_token_ids.cpu().numpy().tolist())\n",
    "#     adv_suffix_string = tokenizer.decode(adv_token_ids.cpu().numpy())\n",
    "#     final_string_ids = torch.hstack([inputs_token_ids, adv_token_ids])\n",
    "#     outputs = []\n",
    "#     generation_loop = range(1)\n",
    "#     import warnings\n",
    "#     # Suppress specific warnings\n",
    "#     warnings.filterwarnings(\"ignore\", message=\".*`do_sample` is set to `False`. However, `temperature` is set to.*\")\n",
    "#     warnings.filterwarnings(\"ignore\", message=\".*`do_sample` is set to `False`. However, `top_p` is set to.*\")\n",
    "    \n",
    "#     ######## Discrete tokens for Output Generation ########\n",
    "#     for loop in tqdm(generation_loop, desc=\"Generating outputs\", leave=False):\n",
    "#         generated_output = model.generate(final_string_ids.unsqueeze(0), \n",
    "#                                           max_length=num_tokens, \n",
    "#                                           pad_token_id=tokenizer.pad_token_id,\n",
    "#                                           do_sample=False)\n",
    "#         generated_output_string = tokenizer.decode(generated_output[0][:].cpu().numpy(), skip_special_tokens=True).strip()\n",
    "#         outputs.append(generated_output_string)\n",
    "    \n",
    "#     iteration_result = {\n",
    "#         \"harmful-behaviour\": user_prompt,\n",
    "#         \"target\": target,\n",
    "#         \"suffix_token_ids\": adv_suffix_list,\n",
    "#         \"suffix_string\": adv_suffix_string,\n",
    "#         \"epoch_no\": epoch_no,\n",
    "#         \"continuous_loss\": continuous_loss,\n",
    "#         \"discrete_loss\": discrete_loss,\n",
    "#         \"best_disc_loss\":best_disc_loss,\n",
    "#         \"epch_at_best_disc_loss\": best_loss_at_epoch,\n",
    "#         \"outputs\": outputs\n",
    "#     }\n",
    "#     optimization_results.append(iteration_result)\n",
    "\n",
    "#     # Update the JSON File\n",
    "#     with open(json_file_path, \"w\") as f:\n",
    "#         json.dump(\n",
    "#             optimization_results,\n",
    "#             f,\n",
    "#             indent=4,  # Keep structure readable\n",
    "#             ensure_ascii=False  # Do this to Handle non-ASCII chars properly; If there is any\n",
    "#         )\n",
    "\n",
    "#     ##########################################################################################\n",
    "#     ## Create and Update a JSONL file (required for running the parse_results.ipynb script) ##\n",
    "#     output_file = directories[1]+\"/EGD_with_Adam_\"+model_name+\"(\"+str(len(harmful_behaviors))+\"_behaviors)(\"+str(num_steps)+\"_steps).jsonl\"\n",
    "#     from behavior import Behavior\n",
    "#     behavior = Behavior(user_prompt, adv_suffix_string, generated_output_string, \"\", \"\")\n",
    "    \n",
    "#     with open(output_file, 'a') as f:\n",
    "#         f.write(json.dumps(behavior.to_dict()) + '\\n')\n",
    "#     f.close()  \n",
    "#     ## Create and Update a JSONL file (required for running the parse_results.ipynb script) ##\n",
    "#     ########################################################################################## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def universal_suffix_attack(\n",
    "#     model,\n",
    "#     tokenizer,\n",
    "#     harmful_behaviors: List[Tuple[str, str]],\n",
    "#     embed_weights: torch.Tensor,\n",
    "#     device: str,\n",
    "#     model_name: str,\n",
    "#     dataset_name: str,\n",
    "#     suffix_len: int = 20,\n",
    "#     num_steps: int = 10,\n",
    "#     step_size: float = 1e-2,\n",
    "#     initial_coefficient: float = 1e-5,\n",
    "#     final_coefficient: float = 1e-3,\n",
    "#     Optimizer = torch.optim.Adam  # Replace with your custom optimizer class if needed\n",
    "# ):\n",
    "#     # Directories\n",
    "#     directories = [f'./Multi-Prompt/CSV_Files/{model_name}/{dataset_name}', \n",
    "#                    f'./Multi-Prompt/JSON_Files/{model_name}/{dataset_name}']\n",
    "#     os.makedirs(directories[0], exist_ok=True)\n",
    "#     os.makedirs(directories[1], exist_ok=True)\n",
    "\n",
    "#     # Prompt-token list\n",
    "#     prompt_embeds_list = []\n",
    "#     target_embeds_list = []\n",
    "#     target_one_hot_list = []    \n",
    "\n",
    "#     for user_prompt, target in harmful_behaviors:\n",
    "#         user_prompt_tokens = get_tokens(user_prompt, tokenizer=tokenizer, device=device)\n",
    "#         target_tokens = get_tokens(target, tokenizer=tokenizer, device=device)[1:]\n",
    "#         one_hot_inputs, emb_user = create_one_hot_and_embeddings(user_prompt_tokens, embed_weights, device)\n",
    "#         one_hot_target, emb_target = create_one_hot_and_embeddings(target_tokens, embed_weights, device)\n",
    "#         prompt_embeds_list.append(emb_user.unsqueeze(0))\n",
    "#         target_embeds_list.append(emb_target.unsqueeze(0))\n",
    "#         target_one_hot_list.append(one_hot_target.unsqueeze(0))\n",
    "\n",
    "#     # Suffix and optimizer\n",
    "#     one_hot_adv = F.softmax(torch.rand(suffix_len, embed_weights.shape[0], dtype=torch.float16, device=device), dim=1).to(embed_weights.dtype)\n",
    "#     one_hot_adv.requires_grad_()\n",
    "#     optimizer = Optimizer([one_hot_adv], lr=step_size)\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=50)\n",
    "\n",
    "#     # Keep track of the best discrete loss\n",
    "#     # and the corresponding one-hot representation\n",
    "#     # of the adversarial suffix\n",
    "#     best_disc_loss = np.inf\n",
    "#     best_loss_at_epoch = 0\n",
    "#     effective_adv_one_hot = one_hot_adv\n",
    "    \n",
    "#     # CSV and JSON init\n",
    "#     timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#     csv_filename = os.path.join(directories[0], f'universal_suffix_log_{timestamp}.csv')\n",
    "#     json_filename = os.path.join(directories[1], f'universal_suffix_outputs_{timestamp}.json')\n",
    "\n",
    "#     column_names = ['epoch', 'learning_rate', 'avg_continuous_loss', 'avg_discrete_loss']\n",
    "#     for i in range(1, suffix_len+1):\n",
    "#         column_names += [f'max_{i}', f'token_id_{i}']\n",
    "#     df = pd.DataFrame(columns=column_names)\n",
    "#     results = []\n",
    "\n",
    "#     # Training\n",
    "#     for epoch_no in tqdm(range(num_steps), desc=\"Training Universal Suffix\"):\n",
    "#         optimizer.zero_grad()\n",
    "#         total_loss = 0.0\n",
    "#         total_discrete_loss = 0.0\n",
    "#         accumulated_grads = torch.zeros_like(one_hot_adv)\n",
    "\n",
    "#         for emb_user, emb_target, one_hot_target in zip(prompt_embeds_list, target_embeds_list, target_one_hot_list):\n",
    "#             emb_adv = (one_hot_adv @ embed_weights).unsqueeze(0)\n",
    "#             ce_loss, _ = calc_loss(model, emb_user, emb_adv, emb_target, one_hot_target)\n",
    "\n",
    "#             masked = one_hot_adv.clone()\n",
    "#             adv_token_ids = torch.argmax(masked, dim=1)\n",
    "#             one_hot_discrete = torch.zeros_like(one_hot_adv)\n",
    "#             one_hot_discrete.scatter_(1, adv_token_ids.unsqueeze(1), 1.0)\n",
    "#             emb_adv_discrete = (one_hot_discrete @ embed_weights).unsqueeze(0)\n",
    "#             disc_loss, _ = calc_loss(model, emb_user, emb_adv_discrete, emb_target, one_hot_target)\n",
    "#             # If loss improves, save it as x_best\n",
    "#             discrete_loss =  disc_loss.detach().cpu().item()\n",
    "#             # cur_loss_list.append(cur_loss)\n",
    "#             if discrete_loss < best_disc_loss:\n",
    "#                 # print(f\"########## {discrete_loss} #########\")\n",
    "#                 best_disc_loss = discrete_loss\n",
    "#                 best_loss_at_epoch = epoch_no\n",
    "#                 effective_adv_one_hot = one_hot_discrete\n",
    "\n",
    "#             eps = 1e-12\n",
    "#             log_one_hot = torch.log(one_hot_adv.to(torch.float32) + eps)\n",
    "#             entropy_term = -(one_hot_adv * (log_one_hot - 1)).sum()\n",
    "#             kl_term = -torch.log(torch.max(one_hot_adv, dim=1).values + eps).sum()\n",
    "\n",
    "#             reg_coeff = initial_coefficient * (final_coefficient / initial_coefficient) ** (epoch_no / (num_steps - 1))\n",
    "#             reg_loss = ce_loss - reg_coeff * entropy_term + reg_coeff * kl_term\n",
    "#             reg_loss.backward(retain_graph=True)\n",
    "#             accumulated_grads += one_hot_adv.grad.clone()\n",
    "#             one_hot_adv.grad.zero_()\n",
    "\n",
    "#             total_loss += reg_loss.detach().cpu().item()\n",
    "#             total_discrete_loss+=discrete_loss\n",
    "\n",
    "#         accumulated_grads = accumulated_grads / len(prompt_embeds_list)\n",
    "#         accumulated_grads = F.normalize(accumulated_grads, p=2.0, dim=1)\n",
    "#         one_hot_adv.grad = accumulated_grads\n",
    "#         torch.nn.utils.clip_grad_norm_([one_hot_adv], max_norm=1.0)\n",
    "#         optimizer.step()\n",
    "#         scheduler.step(total_loss / len(prompt_embeds_list))\n",
    "\n",
    "#         avg_cont_loss = total_loss / len(prompt_embeds_list)\n",
    "#         avg_disc_loss = total_discrete_loss / len(prompt_embeds_list)\n",
    "\n",
    "#         max_vals = torch.max(one_hot_adv, dim=1)\n",
    "#         row = [epoch_no, optimizer.param_groups[0]['lr'], avg_cont_loss, avg_disc_loss]\n",
    "#         row += max_vals.values.detach().cpu().numpy().tolist()\n",
    "#         row += max_vals.indices.detach().cpu().numpy().tolist()\n",
    "#         df.loc[len(df)] = row\n",
    "\n",
    "#         adv_token_ids = max_vals.indices\n",
    "#         adv_suffix_str = tokenizer.decode(adv_token_ids.detach().cpu().numpy())\n",
    "#         results.append({\n",
    "#             \"epoch\": epoch_no,\n",
    "#             \"adv_suffix_str\": adv_suffix_str,\n",
    "#             \"suffix_token_ids\": adv_token_ids.detach().cpu().tolist(),\n",
    "#             \"avg_continuous_loss\": avg_cont_loss,\n",
    "#             \"avg_discrete_loss\": avg_disc_loss,\n",
    "#             \"best_disc_loss\": best_disc_loss,\n",
    "#             \"best_loss_at_epoch\": best_loss_at_epoch\n",
    "#         })\n",
    "\n",
    "#     df.to_csv(csv_filename, index=False)\n",
    "#     with open(json_filename, \"w\") as f:\n",
    "#         json.dump(results, f, indent=4)\n",
    "\n",
    "#     return effective_adv_one_hot.detach(), results, df\n",
    "#     # return one_hot_adv.detach(), results, df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-embedding-attack_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
